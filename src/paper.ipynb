{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_utils import get_all_regressors\n",
    "import pandas as pd\n",
    "from PersistenceManager import PersistenceManager\n",
    "from predictions import create_model_machine_learning_algorithm\n",
    "from own_utils import load_json\n",
    "from cleaning import prepare_dataframe_from_db, process_time_series_data\n",
    "from predictions import run_time_series_prediction_pipeline, process_model_machine_learning, evaluate_model\n",
    "from own_utils import execute_concurrently\n",
    "from own_utils import list_directories_by_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_data</th>\n",
       "      <th>id_device</th>\n",
       "      <th>id_sensor</th>\n",
       "      <th>id_variable</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>id_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:31:00</td>\n",
       "      <td>18.57</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:32:00</td>\n",
       "      <td>18.56</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:33:00</td>\n",
       "      <td>18.55</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:34:00</td>\n",
       "      <td>18.53</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:35:00</td>\n",
       "      <td>18.53</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527268</th>\n",
       "      <td>3261165</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:10</td>\n",
       "      <td>31.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527269</th>\n",
       "      <td>3261166</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:20</td>\n",
       "      <td>37.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527270</th>\n",
       "      <td>3261167</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:30</td>\n",
       "      <td>25.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527271</th>\n",
       "      <td>3261168</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:40</td>\n",
       "      <td>26.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527272</th>\n",
       "      <td>3261169</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527273 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_data id_device id_sensor id_variable            timestamp  value  \\\n",
       "0              1   DBEM003      sWEA     00-temp  2023-04-18 09:31:00  18.57   \n",
       "1              2   DBEM003      sWEA     00-temp  2023-04-18 09:32:00  18.56   \n",
       "2              3   DBEM003      sWEA     00-temp  2023-04-18 09:33:00  18.55   \n",
       "3              4   DBEM003      sWEA     00-temp  2023-04-18 09:34:00  18.53   \n",
       "4              5   DBEM003      sWEA     00-temp  2023-04-18 09:35:00  18.53   \n",
       "...          ...       ...       ...         ...                  ...    ...   \n",
       "1527268  3261165   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:10  31.00   \n",
       "1527269  3261166   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:20  37.00   \n",
       "1527270  3261167   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:30  25.00   \n",
       "1527271  3261168   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:40  26.00   \n",
       "1527272  3261169   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:50  21.00   \n",
       "\n",
       "        unit  id_location  \n",
       "0         ºC          NaN  \n",
       "1         ºC          NaN  \n",
       "2         ºC          NaN  \n",
       "3         ºC          NaN  \n",
       "4         ºC          NaN  \n",
       "...      ...          ...  \n",
       "1527268  ppb          NaN  \n",
       "1527269  ppb          NaN  \n",
       "1527270  ppb          NaN  \n",
       "1527271  ppb          NaN  \n",
       "1527272  ppb          NaN  \n",
       "\n",
       "[1527273 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'..\\data\\instants_data_saved\\2023-07-04_12-09-22.csv')\n",
    "df = df.query(\"id_device == 'DBEM003'\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataframe_from_db_cols_for_query = [\n",
    "    \"00-eco2\",\n",
    "    \"00-temp\",\n",
    "    \"01-hum\",\n",
    "    \"01-tvoc\",\n",
    "    \"02-pres\",\n",
    "    \"03-siaq\",\n",
    "    \"04-diaq\"\n",
    "]\n",
    "preprocess_time_series_data_resample_freq = \"60S\"\n",
    "preprocess_time_series_data_aggregation_func = \"mean\"\n",
    "preprocess_time_series_data_method = \"linear\"\n",
    "preprocess_time_series_data_outlier_cols = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_device</th>\n",
       "      <th>id_sensor</th>\n",
       "      <th>id_variable</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>id_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:31:00+00:00</td>\n",
       "      <td>18.57</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:32:00+00:00</td>\n",
       "      <td>18.56</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:33:00+00:00</td>\n",
       "      <td>18.55</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:34:00+00:00</td>\n",
       "      <td>18.53</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:35:00+00:00</td>\n",
       "      <td>18.53</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187874</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:10+00:00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187875</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:20+00:00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187876</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:30+00:00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187877</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:40+00:00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187878</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-10 23:59:50+00:00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187879 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_device id_sensor id_variable                  timestamp  value  \\\n",
       "0         DBEM003      sWEA     00-temp  2023-04-18 09:31:00+00:00  18.57   \n",
       "1         DBEM003      sWEA     00-temp  2023-04-18 09:32:00+00:00  18.56   \n",
       "2         DBEM003      sWEA     00-temp  2023-04-18 09:33:00+00:00  18.55   \n",
       "3         DBEM003      sWEA     00-temp  2023-04-18 09:34:00+00:00  18.53   \n",
       "4         DBEM003      sWEA     00-temp  2023-04-18 09:35:00+00:00  18.53   \n",
       "...           ...       ...         ...                        ...    ...   \n",
       "1187874   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:10+00:00  31.00   \n",
       "1187875   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:20+00:00  37.00   \n",
       "1187876   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:30+00:00  25.00   \n",
       "1187877   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:40+00:00  26.00   \n",
       "1187878   DBEM003      sAQU     01-tvoc  2023-05-10 23:59:50+00:00  21.00   \n",
       "\n",
       "        unit  id_location  \n",
       "0         ºC          NaN  \n",
       "1         ºC          NaN  \n",
       "2         ºC          NaN  \n",
       "3         ºC          NaN  \n",
       "4         ºC          NaN  \n",
       "...      ...          ...  \n",
       "1187874  ppb          NaN  \n",
       "1187875  ppb          NaN  \n",
       "1187876  ppb          NaN  \n",
       "1187877  ppb          NaN  \n",
       "1187878  ppb          NaN  \n",
       "\n",
       "[1187879 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare_dataframe_from_db(\n",
    "    df=df,\n",
    "    cols_for_query = prepare_dataframe_from_db_cols_for_query,\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_device</th>\n",
       "      <th>id_sensor</th>\n",
       "      <th>id_variable</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>00-eco2</td>\n",
       "      <td>2023-04-18 09:31:00+00:00</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>00-eco2</td>\n",
       "      <td>2023-04-18 09:32:00+00:00</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>00-eco2</td>\n",
       "      <td>2023-04-18 09:33:00+00:00</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>00-eco2</td>\n",
       "      <td>2023-04-18 09:34:00+00:00</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>00-eco2</td>\n",
       "      <td>2023-04-18 09:35:00+00:00</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227838</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>04-diaq</td>\n",
       "      <td>2023-05-10 23:55:00+00:00</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227839</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>04-diaq</td>\n",
       "      <td>2023-05-10 23:56:00+00:00</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227840</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>04-diaq</td>\n",
       "      <td>2023-05-10 23:57:00+00:00</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227841</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>04-diaq</td>\n",
       "      <td>2023-05-10 23:58:00+00:00</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227842</th>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>04-diaq</td>\n",
       "      <td>2023-05-10 23:59:00+00:00</td>\n",
       "      <td>30.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227843 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_device id_sensor id_variable                 timestamp       value\n",
       "0        DBEM003      sAQU     00-eco2 2023-04-18 09:31:00+00:00  400.000000\n",
       "1        DBEM003      sAQU     00-eco2 2023-04-18 09:32:00+00:00  400.000000\n",
       "2        DBEM003      sAQU     00-eco2 2023-04-18 09:33:00+00:00  400.000000\n",
       "3        DBEM003      sAQU     00-eco2 2023-04-18 09:34:00+00:00  400.000000\n",
       "4        DBEM003      sAQU     00-eco2 2023-04-18 09:35:00+00:00  400.000000\n",
       "...          ...       ...         ...                       ...         ...\n",
       "227838   DBEM003      sWEA     04-diaq 2023-05-10 23:55:00+00:00   26.666667\n",
       "227839   DBEM003      sWEA     04-diaq 2023-05-10 23:56:00+00:00   28.000000\n",
       "227840   DBEM003      sWEA     04-diaq 2023-05-10 23:57:00+00:00   29.000000\n",
       "227841   DBEM003      sWEA     04-diaq 2023-05-10 23:58:00+00:00   30.333333\n",
       "227842   DBEM003      sWEA     04-diaq 2023-05-10 23:59:00+00:00   30.166667\n",
       "\n",
       "[227843 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process time series data: resample and interpolate\n",
    "df_resampled_interpolated = process_time_series_data(\n",
    "    df=df,\n",
    "    resample_freq = preprocess_time_series_data_resample_freq,\n",
    "    aggregation_func = preprocess_time_series_data_aggregation_func,\n",
    "    method = preprocess_time_series_data_method,\n",
    "    outlier_cols = preprocess_time_series_data_outlier_cols,\n",
    ")\n",
    "df_resampled_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id_device</th>\n",
       "      <th colspan=\"7\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>00-eco2</th>\n",
       "      <th>00-temp</th>\n",
       "      <th>01-hum</th>\n",
       "      <th>01-tvoc</th>\n",
       "      <th>02-pres</th>\n",
       "      <th>03-siaq</th>\n",
       "      <th>04-diaq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-18 09:31:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>934.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-18 09:32:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.560000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>934.720000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-18 09:33:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>33.030000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>934.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-18 09:34:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>934.660000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-18 09:35:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>934.680000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32544</th>\n",
       "      <td>2023-05-10 23:55:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>449.833333</td>\n",
       "      <td>25.281667</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>939.910000</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32545</th>\n",
       "      <td>2023-05-10 23:56:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>25.278333</td>\n",
       "      <td>29.221667</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>939.913333</td>\n",
       "      <td>27.166667</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32546</th>\n",
       "      <td>2023-05-10 23:57:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>414.500000</td>\n",
       "      <td>25.271667</td>\n",
       "      <td>29.205000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>939.873333</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>2023-05-10 23:58:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>407.166667</td>\n",
       "      <td>25.268333</td>\n",
       "      <td>29.241667</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>939.873333</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32548</th>\n",
       "      <td>2023-05-10 23:59:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>25.275000</td>\n",
       "      <td>29.125000</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>939.843333</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>30.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32549 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            timestamp id_device       value             \\\n",
       "id_variable                                         00-eco2    00-temp   \n",
       "0           2023-04-18 09:31:00+00:00   DBEM003  400.000000  18.570000   \n",
       "1           2023-04-18 09:32:00+00:00   DBEM003  400.000000  18.560000   \n",
       "2           2023-04-18 09:33:00+00:00   DBEM003  400.000000  18.550000   \n",
       "3           2023-04-18 09:34:00+00:00   DBEM003  400.000000  18.530000   \n",
       "4           2023-04-18 09:35:00+00:00   DBEM003  400.000000  18.530000   \n",
       "...                               ...       ...         ...        ...   \n",
       "32544       2023-05-10 23:55:00+00:00   DBEM003  449.833333  25.281667   \n",
       "32545       2023-05-10 23:56:00+00:00   DBEM003  427.000000  25.278333   \n",
       "32546       2023-05-10 23:57:00+00:00   DBEM003  414.500000  25.271667   \n",
       "32547       2023-05-10 23:58:00+00:00   DBEM003  407.166667  25.268333   \n",
       "32548       2023-05-10 23:59:00+00:00   DBEM003  423.000000  25.275000   \n",
       "\n",
       "                                                                     \n",
       "id_variable     01-hum    01-tvoc     02-pres    03-siaq    04-diaq  \n",
       "0            33.050000   2.000000  934.700000  25.000000  27.000000  \n",
       "1            33.000000   1.000000  934.720000  25.000000  25.000000  \n",
       "2            33.030000   8.000000  934.700000  25.000000  25.000000  \n",
       "3            33.090000   4.000000  934.660000  25.000000  26.000000  \n",
       "4            33.050000   3.000000  934.680000  26.000000  29.000000  \n",
       "...                ...        ...         ...        ...        ...  \n",
       "32544        29.266667  38.000000  939.910000  26.166667  26.666667  \n",
       "32545        29.221667  39.333333  939.913333  27.166667  28.000000  \n",
       "32546        29.205000  22.333333  939.873333  27.666667  29.000000  \n",
       "32547        29.241667  16.166667  939.873333  28.833333  30.333333  \n",
       "32548        29.125000  25.666667  939.843333  28.833333  30.166667  \n",
       "\n",
       "[32549 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Pivot and rename columns for uniformity\n",
    "df_preprocessed = pd.pivot_table(\n",
    "    df_resampled_interpolated.reset_index()[[\"timestamp\", \"id_device\", \"id_variable\", \"value\"]],\n",
    "    index=[\"timestamp\", \"id_device\"],\n",
    "    columns=[\"id_variable\"]\n",
    ").reset_index()\n",
    "\n",
    "df_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id_device</th>\n",
       "      <th>y</th>\n",
       "      <th>00-temp</th>\n",
       "      <th>01-hum</th>\n",
       "      <th>01-tvoc</th>\n",
       "      <th>02-pres</th>\n",
       "      <th>03-siaq</th>\n",
       "      <th>04-diaq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-18 09:31:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>934.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-18 09:32:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.560000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>934.720000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-18 09:33:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>33.030000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>934.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-18 09:34:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>934.660000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-18 09:35:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>934.680000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32544</th>\n",
       "      <td>2023-05-10 23:55:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>449.833333</td>\n",
       "      <td>25.281667</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>939.910000</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32545</th>\n",
       "      <td>2023-05-10 23:56:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>25.278333</td>\n",
       "      <td>29.221667</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>939.913333</td>\n",
       "      <td>27.166667</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32546</th>\n",
       "      <td>2023-05-10 23:57:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>414.500000</td>\n",
       "      <td>25.271667</td>\n",
       "      <td>29.205000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>939.873333</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>2023-05-10 23:58:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>407.166667</td>\n",
       "      <td>25.268333</td>\n",
       "      <td>29.241667</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>939.873333</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32548</th>\n",
       "      <td>2023-05-10 23:59:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>25.275000</td>\n",
       "      <td>29.125000</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>939.843333</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>30.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32549 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp id_device           y    00-temp     01-hum  \\\n",
       "0     2023-04-18 09:31:00+00:00   DBEM003  400.000000  18.570000  33.050000   \n",
       "1     2023-04-18 09:32:00+00:00   DBEM003  400.000000  18.560000  33.000000   \n",
       "2     2023-04-18 09:33:00+00:00   DBEM003  400.000000  18.550000  33.030000   \n",
       "3     2023-04-18 09:34:00+00:00   DBEM003  400.000000  18.530000  33.090000   \n",
       "4     2023-04-18 09:35:00+00:00   DBEM003  400.000000  18.530000  33.050000   \n",
       "...                         ...       ...         ...        ...        ...   \n",
       "32544 2023-05-10 23:55:00+00:00   DBEM003  449.833333  25.281667  29.266667   \n",
       "32545 2023-05-10 23:56:00+00:00   DBEM003  427.000000  25.278333  29.221667   \n",
       "32546 2023-05-10 23:57:00+00:00   DBEM003  414.500000  25.271667  29.205000   \n",
       "32547 2023-05-10 23:58:00+00:00   DBEM003  407.166667  25.268333  29.241667   \n",
       "32548 2023-05-10 23:59:00+00:00   DBEM003  423.000000  25.275000  29.125000   \n",
       "\n",
       "         01-tvoc     02-pres    03-siaq    04-diaq  \n",
       "0       2.000000  934.700000  25.000000  27.000000  \n",
       "1       1.000000  934.720000  25.000000  25.000000  \n",
       "2       8.000000  934.700000  25.000000  25.000000  \n",
       "3       4.000000  934.660000  25.000000  26.000000  \n",
       "4       3.000000  934.680000  26.000000  29.000000  \n",
       "...          ...         ...        ...        ...  \n",
       "32544  38.000000  939.910000  26.166667  26.666667  \n",
       "32545  39.333333  939.913333  27.166667  28.000000  \n",
       "32546  22.333333  939.873333  27.666667  29.000000  \n",
       "32547  16.166667  939.873333  28.833333  30.333333  \n",
       "32548  25.666667  939.843333  28.833333  30.166667  \n",
       "\n",
       "[32549 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preprocessed.columns = [\n",
    "    col[0] if col[-1] == '' else col[-1]\n",
    "    for col in df_preprocessed.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "df_preprocessed.rename(columns={\"00-eco2\":\"y\"}, inplace=True)\n",
    "\n",
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp', '02-pres']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df_preprocessed.columns)-set(['y','timestamp','id_device']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp', '02-pres', 'y']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df_preprocessed.columns)-set(['y','timestamp','id_device'])) + [\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function of standarization DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id_device</th>\n",
       "      <th>y</th>\n",
       "      <th>00-temp</th>\n",
       "      <th>01-hum</th>\n",
       "      <th>01-tvoc</th>\n",
       "      <th>02-pres</th>\n",
       "      <th>03-siaq</th>\n",
       "      <th>04-diaq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-18 09:31:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>934.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-18 09:32:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.560000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>934.720000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-18 09:33:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>33.030000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>934.700000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-18 09:34:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>33.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>934.660000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-18 09:35:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>934.680000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32544</th>\n",
       "      <td>2023-05-10 23:55:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>449.833333</td>\n",
       "      <td>25.281667</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>939.910000</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32545</th>\n",
       "      <td>2023-05-10 23:56:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>25.278333</td>\n",
       "      <td>29.221667</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>939.913333</td>\n",
       "      <td>27.166667</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32546</th>\n",
       "      <td>2023-05-10 23:57:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>414.500000</td>\n",
       "      <td>25.271667</td>\n",
       "      <td>29.205000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>939.873333</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>2023-05-10 23:58:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>407.166667</td>\n",
       "      <td>25.268333</td>\n",
       "      <td>29.241667</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>939.873333</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32548</th>\n",
       "      <td>2023-05-10 23:59:00+00:00</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>25.275000</td>\n",
       "      <td>29.125000</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>939.843333</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>30.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32549 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp id_device           y    00-temp     01-hum  \\\n",
       "0     2023-04-18 09:31:00+00:00   DBEM003  400.000000  18.570000  33.050000   \n",
       "1     2023-04-18 09:32:00+00:00   DBEM003  400.000000  18.560000  33.000000   \n",
       "2     2023-04-18 09:33:00+00:00   DBEM003  400.000000  18.550000  33.030000   \n",
       "3     2023-04-18 09:34:00+00:00   DBEM003  400.000000  18.530000  33.090000   \n",
       "4     2023-04-18 09:35:00+00:00   DBEM003  400.000000  18.530000  33.050000   \n",
       "...                         ...       ...         ...        ...        ...   \n",
       "32544 2023-05-10 23:55:00+00:00   DBEM003  449.833333  25.281667  29.266667   \n",
       "32545 2023-05-10 23:56:00+00:00   DBEM003  427.000000  25.278333  29.221667   \n",
       "32546 2023-05-10 23:57:00+00:00   DBEM003  414.500000  25.271667  29.205000   \n",
       "32547 2023-05-10 23:58:00+00:00   DBEM003  407.166667  25.268333  29.241667   \n",
       "32548 2023-05-10 23:59:00+00:00   DBEM003  423.000000  25.275000  29.125000   \n",
       "\n",
       "         01-tvoc     02-pres    03-siaq    04-diaq  \n",
       "0       2.000000  934.700000  25.000000  27.000000  \n",
       "1       1.000000  934.720000  25.000000  25.000000  \n",
       "2       8.000000  934.700000  25.000000  25.000000  \n",
       "3       4.000000  934.660000  25.000000  26.000000  \n",
       "4       3.000000  934.680000  26.000000  29.000000  \n",
       "...          ...         ...        ...        ...  \n",
       "32544  38.000000  939.910000  26.166667  26.666667  \n",
       "32545  39.333333  939.913333  27.166667  28.000000  \n",
       "32546  22.333333  939.873333  27.666667  29.000000  \n",
       "32547  16.166667  939.873333  28.833333  30.333333  \n",
       "32548  25.666667  939.843333  28.833333  30.166667  \n",
       "\n",
       "[32549 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_and_standardize_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    resample_freq: str,\n",
    "    aggregation_func: str,\n",
    "    interpolation_method: str,\n",
    "    target_variable: str,\n",
    "    outlier_cols: list = None,\n",
    "    pivot: bool = False,\n",
    "    pivot_index: list = None,\n",
    "    pivot_columns: list = None,\n",
    "    pivot_values: list = None,\n",
    "    subset_cols: list = None,\n",
    "    target_column_name: str = \"y\",\n",
    "    save_metadata: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess and standardize a dataframe for cross-validation.\n",
    "\n",
    "    This function processes time-series data with resampling, aggregation, and interpolation. \n",
    "    Optionally, it applies a pivot operation to reshape the dataframe into a standardized format.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to preprocess and standardize.\n",
    "    resample_freq : str\n",
    "        Frequency for resampling the time-series data.\n",
    "    aggregation_func : str\n",
    "        Aggregation function to apply during resampling.\n",
    "    interpolation_method : str\n",
    "        Method to use for interpolating missing values.\n",
    "    target_variable : str, optional\n",
    "        The name of the column to set as the target variable (default is None).\n",
    "    outlier_cols : list, optional\n",
    "        List of columns to apply outlier handling (default is None, no outlier handling applied).\n",
    "    pivot : bool, optional\n",
    "        Whether to apply a pivot operation to the dataframe (default is False).\n",
    "    pivot_index : list, optional\n",
    "        Columns to use as the index in the pivot table (required if `pivot=True`).\n",
    "    pivot_columns : list, optional\n",
    "        Columns to use as the columns in the pivot table (required if `pivot=True`).\n",
    "    pivot_values : list, optional\n",
    "        Columns to use as the values in the pivot table (required if `pivot=True`).\n",
    "    subset_cols : list, optional\n",
    "        Columns to subset the dataframe to (default is None, no subsetting applied).\n",
    "    target_column_name : str, optional\n",
    "        The new name for the target variable column in the standardized dataframe (default is \"y\").\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A preprocessed and standardized dataframe ready for further analysis or modeling.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    ```python\n",
    "    df_preprocessed = preprocess_and_standardize_dataframe(\n",
    "        df=my_df,\n",
    "        resample_freq=\"60S\",\n",
    "        aggregation_func=\"mean\",\n",
    "        interpolation_method=\"linear\",\n",
    "        target_variable=\"00-eco2\",\n",
    "        pivot=True,\n",
    "        pivot_index=[\"timestamp\", \"id_device\"],\n",
    "        pivot_columns=[\"id_variable\"],\n",
    "        pivot_values=[\"value\"]\n",
    "    )\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Process time-series data: resample, aggregate, and interpolate\n",
    "    df_resampled_interpolated = process_time_series_data(\n",
    "        df=df,\n",
    "        resample_freq=resample_freq,\n",
    "        aggregation_func=aggregation_func,\n",
    "        method=interpolation_method,\n",
    "        outlier_cols=outlier_cols,\n",
    "    )\n",
    "\n",
    "    # Apply pivot operation if required\n",
    "    if pivot:\n",
    "        if not pivot_index or not pivot_columns or not pivot_values:\n",
    "            raise ValueError(\"`pivot_index`, `pivot_columns`, and `pivot_values` must be provided if `pivot=True`.\")\n",
    "        \n",
    "        df_resampled_interpolated = pd.pivot_table(\n",
    "            df_resampled_interpolated.reset_index()[subset_cols],\n",
    "            index=pivot_index,\n",
    "            columns=pivot_columns,\n",
    "            values=pivot_values\n",
    "        ).reset_index()\n",
    "\n",
    "        # Flatten column hierarchy if created by pivot_table\n",
    "        df_resampled_interpolated.columns = [\n",
    "            col[0] if col[-1] == '' else col[-1]\n",
    "            for col in df_resampled_interpolated.columns.to_flat_index()\n",
    "        ]\n",
    "\n",
    "    # Rename target variable column if specified\n",
    "    if target_variable:\n",
    "        df_resampled_interpolated.rename(columns={target_variable: target_column_name}, inplace=True)\n",
    "\n",
    "    return df_resampled_interpolated\n",
    "\n",
    "df = pd.read_csv(r'..\\data\\instants_data_saved\\2023-07-04_12-09-22.csv')\n",
    "df = df.query(\"id_device == 'DBEM003'\").reset_index(drop=True)\n",
    "prepare_dataframe_from_db_cols_for_query = [\n",
    "    \"00-eco2\",\n",
    "    \"00-temp\",\n",
    "    \"01-hum\",\n",
    "    \"01-tvoc\",\n",
    "    \"02-pres\",\n",
    "    \"03-siaq\",\n",
    "    \"04-diaq\"\n",
    "]\n",
    "# Prepare dataframe with selected columns\n",
    "df = prepare_dataframe_from_db(\n",
    "    df=df,\n",
    "    cols_for_query=prepare_dataframe_from_db_cols_for_query,\n",
    ")\n",
    "\n",
    "preprocess_time_series_data_resample_freq = \"60S\"\n",
    "preprocess_time_series_data_aggregation_func = \"mean\"\n",
    "preprocess_time_series_data_method = \"linear\"\n",
    "target_variable = \"00-eco2\"\n",
    "outlier_cols = None\n",
    "pivot = True\n",
    "pivot_index = [\"timestamp\", \"id_device\"]\n",
    "pivot_columns = [\"id_variable\"]\n",
    "pivot_values = [\"value\"]\n",
    "subset_cols = [\"timestamp\", \"id_device\", \"id_variable\", \"value\"]\n",
    "target_column_name = \"y\"\n",
    "\n",
    "\n",
    "preprocess_time_series_data_outlier_cols = None\n",
    "df_preprocessed = preprocess_and_standardize_dataframe(\n",
    "    df = df,\n",
    "    resample_freq = preprocess_time_series_data_resample_freq,\n",
    "    aggregation_func = preprocess_time_series_data_aggregation_func,\n",
    "    interpolation_method = preprocess_time_series_data_method,\n",
    "    target_variable=target_variable,\n",
    "    outlier_cols=outlier_cols,\n",
    "    pivot=pivot,\n",
    "    pivot_index=pivot_index,\n",
    "    pivot_columns=pivot_columns,\n",
    "    pivot_values=pivot_values,\n",
    "    subset_cols=subset_cols,\n",
    "    target_column_name=target_column_name\n",
    ")\n",
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_data = df_preprocessed  \n",
    "ini_train = \"2023-04-18 00:00:00+00:00\"\n",
    "fin_train = \"2023-04-25 00:00:00+00:00\"\n",
    "fin_test = \"2023-04-26 00:00:00+00:00\"\n",
    "model_sklearn_name = \"ARDRegression\"\n",
    "X_name_features = list(set(df_preprocessed.columns)-set(['y','timestamp','id_device']))\n",
    "Y_name_features = \"y\"\n",
    "n_lags = 10\n",
    "n_leads = 10 \n",
    "lag_columns = list(set(df_preprocessed.columns)-set(['y','timestamp','id_device'])) + [\"y\"]\n",
    "lead_columns = \"y\"\n",
    "scale_in_preprocessing=True\n",
    "name_time_column=\"timestamp\"\n",
    "name_id_sensor_column=\"id_device\"\n",
    "save_preprocessing=True\n",
    "path_to_save_model= \"paper\"\n",
    "folder_name_model= model_sklearn_name\n",
    "folder_name_time_execution=\"execution-time-no-defined\"\n",
    "folder_name_preprocessed_data=\"preprocessed-data-to-use-in-model\"\n",
    "machine_learning_model_args= {\n",
    "    \"max_iter\": 300,\n",
    "    \"tol\": 0.001,\n",
    "    \"alpha_1\": 1e-06,\n",
    "    \"alpha_2\": 1e-06,\n",
    "    \"lambda_1\": 1e-06,\n",
    "    \"lambda_2\": 1e-06,\n",
    "    \"compute_score\": False,\n",
    "    \"threshold_lambda\": 10000.0,\n",
    "    \"fit_intercept\": True,\n",
    "    \"copy_X\": True,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "measure_time = True\n",
    "logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_machine_learning = create_model_machine_learning_algorithm(\n",
    "    tidy_data = tidy_data,\n",
    "    ini_train = ini_train,\n",
    "    fin_train = fin_train,\n",
    "    fin_test = fin_test,\n",
    "    model_sklearn_name = model_sklearn_name,\n",
    "    X_name_features = X_name_features,\n",
    "    Y_name_features = Y_name_features,\n",
    "    n_lags = n_lags,\n",
    "    n_leads = n_leads,\n",
    "    lag_columns = lag_columns,\n",
    "    lead_columns = lead_columns,\n",
    "    scale_in_preprocessing = scale_in_preprocessing,\n",
    "    name_time_column = name_time_column,\n",
    "    save_preprocessing = save_preprocessing,\n",
    "    path_to_save_model = path_to_save_model,\n",
    "    folder_name_model = folder_name_model,\n",
    "    folder_name_time_execution = folder_name_time_execution,\n",
    "    folder_name_preprocessed_data = folder_name_preprocessed_data,\n",
    "    machine_learning_model_args = machine_learning_model_args,\n",
    "    measure_time = measure_time,\n",
    "    logger = logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiples hiperparameters concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import concurrent.futures\n",
    "# import logging\n",
    "# from typing import List, Dict, Callable\n",
    "\n",
    "# #TODO: Arreglar el logger\n",
    "# def machine_learning_concurrently(\n",
    "#     model_func: Callable,\n",
    "#     hyperparameter_combinations: List[Dict],\n",
    "#     data: pd.DataFrame,\n",
    "#     logger: logging.Logger = None\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Executes multiple machine learning concurrently with different hyperparameter sets.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - model_func (Callable): The function that trains (or another step in pipeline) the model.\n",
    "#     - hyperparameter_combinations (List[Dict]): A list of dictionaries, where each dictionary contains\n",
    "#                                                 the hyperparameters for the model training.\n",
    "#     - data (pd.DataFrame): The preprocessed DataFrame to be passed to the model function.\n",
    "#     - logger (logging.Logger, optional): A logger object for tracking progress and errors.\n",
    "    \n",
    "#     Returns:\n",
    "#     - List: A list of results from the model function for each hyperparameter set.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Function wrapper to include data and logging\n",
    "#     def wrapped_model_func(hyperparameters):\n",
    "#         try:\n",
    "#             result = model_func(tidy_data=data, **hyperparameters)\n",
    "#             # logger.info(f\"Experiment with params {hyperparameters} completed successfully.\")\n",
    "#             return result\n",
    "#         except Exception as e:\n",
    "#             # logger.error(f\"Experiment with params {hyperparameters} failed. Error: {e}\")\n",
    "#             return e\n",
    "\n",
    "#     # Execute concurrently\n",
    "#     results = execute_concurrently(wrapped_model_func, hyperparameter_combinations)\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def generate_combinations(parameter_space, model_specific_args):\n",
    "    \"\"\"\n",
    "    Generate combinations of parameters for machine learning experiments in an optimized manner.\n",
    "\n",
    "    This function dynamically combines a generic set of parameters with model-specific hyperparameter\n",
    "    domains, ensuring efficient generation of all possible parameter combinations. It avoids the\n",
    "    creation of intermediate lists and unnecessary memory usage by leveraging generator expressions\n",
    "    and efficient dictionary construction.\n",
    "\n",
    "    Parameters:\n",
    "    - parameter_space (dict): A dictionary defining the generic parameters and their possible values.\n",
    "                              This includes common training parameters such as:\n",
    "                              - `ini_train` (list of str): Start dates for training.\n",
    "                              - `fin_train` (list of str): End dates for training.\n",
    "                              - `fin_test` (list of str): End dates for testing.\n",
    "                              - `model_sklearn_name` (list of str): Names of scikit-learn models to evaluate.\n",
    "                              - `n_lags` (list of int): Number of lag features to include.\n",
    "                              - `n_leads` (list of int): Number of lead features to include.\n",
    "                              - `X_name_features` (list of list of str): Lists of feature names for predictors.\n",
    "                              Other parameters can also be included as required.\n",
    "\n",
    "    - model_specific_args (dict): A dictionary mapping each `model_sklearn_name` to its corresponding\n",
    "                                  hyperparameter domains. Each model's domain is defined as a dictionary,\n",
    "                                  where the keys are hyperparameter names and the values are lists of\n",
    "                                  possible values. Example:\n",
    "                                  {\n",
    "                                      \"ARDRegression\": {\n",
    "                                          \"max_iter\": [200, 300],\n",
    "                                          \"tol\": [0.001, 0.01],\n",
    "                                          \"alpha_1\": [1e-06, 1e-05],\n",
    "                                      },\n",
    "                                      \"Ridge\": {\n",
    "                                          \"alpha\": [0.1, 1.0, 10.0],\n",
    "                                          \"solver\": [\"auto\", \"svd\"]\n",
    "                                      }\n",
    "                                  }\n",
    "\n",
    "    Returns:\n",
    "    - Generator[Dict]: A generator that yields dictionaries representing unique parameter combinations.\n",
    "                       Each dictionary contains both the generic parameters and the model-specific\n",
    "                       hyperparameters for one combination. Example output:\n",
    "                       {\n",
    "                           \"ini_train\": \"2023-04-18\",\n",
    "                           \"fin_train\": \"2023-04-25\",\n",
    "                           \"fin_test\": \"2023-04-27\",\n",
    "                           \"model_sklearn_name\": \"ARDRegression\",\n",
    "                           \"n_lags\": 5,\n",
    "                           \"n_leads\": 10,\n",
    "                           \"X_name_features\": [\"feature1\", \"feature2\"],\n",
    "                           \"machine_learning_model_args\": {\n",
    "                               \"max_iter\": 200,\n",
    "                               \"tol\": 0.001,\n",
    "                               \"alpha_1\": 1e-06,\n",
    "                           }\n",
    "                       }\n",
    "    \"\"\"\n",
    "    generic_keys, generic_values = zip(*((k, v) for k, v in parameter_space.items() if k != \"model_sklearn_name\"))\n",
    "    model_names = parameter_space.get(\"model_sklearn_name\", [])\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            **dict(zip(generic_keys, generic_comb)),\n",
    "            \"model_sklearn_name\": model,\n",
    "            \"machine_learning_model_args\": dict(zip(model_args_keys, model_args_comb))\n",
    "        }\n",
    "        for generic_comb in product(*generic_values)\n",
    "        for model in model_names\n",
    "        for model_args_keys, model_args_values in [(list(model_specific_args[model].keys()), list(model_specific_args[model].values()))]\n",
    "        for model_args_comb in product(*model_args_values)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy_data = df_preprocessed  \n",
    "# ini_train = \"2023-04-18 00:00:00+00:00\"\n",
    "# fin_train = \"2023-04-25 00:00:00+00:00\"\n",
    "# fin_test = \"2023-04-26 00:00:00+00:00\"\n",
    "# model_sklearn_name = \"ARDRegression\"\n",
    "# X_name_features = list(set(df_preprocessed.columns)-set(['y','timestamp','id_device']))\n",
    "# Y_name_features = \"y\"\n",
    "# n_lags = 10\n",
    "# n_leads = 10 \n",
    "# lag_columns = list(set(df_preprocessed.columns)-set(['y','timestamp','id_device'])) + [\"y\"]\n",
    "# lead_columns = \"y\"\n",
    "# scale_in_preprocessing=True\n",
    "# name_time_column=\"timestamp\"\n",
    "# save_preprocessing=True\n",
    "# path_to_save_model= \"paper\"\n",
    "# folder_name_model= model_sklearn_name\n",
    "# folder_name_time_execution=\"execution-time-no-defined\"\n",
    "# folder_name_preprocessed_data=\"preprocessed-data-to-use-in-model\"\n",
    "# machine_learning_model_args= {\n",
    "#     \"max_iter\": 300,\n",
    "#     \"tol\": 0.001,\n",
    "#     \"alpha_1\": 1e-06,\n",
    "#     \"alpha_2\": 1e-06,\n",
    "#     \"lambda_1\": 1e-06,\n",
    "#     \"lambda_2\": 1e-06,\n",
    "#     \"compute_score\": False,\n",
    "#     \"threshold_lambda\": 10000.0,\n",
    "#     \"fit_intercept\": True,\n",
    "#     \"copy_X\": True,\n",
    "#     \"verbose\": False,\n",
    "# }\n",
    "# measure_time = True\n",
    "# logger = None\n",
    "hyperparameters_model_space = {\n",
    "    \"tidy_data\": [df_preprocessed],\n",
    "    \"ini_train\": [\"2023-04-18 00:00:00+00:00\", \"2023-04-19 00:00:00+00:00\"],\n",
    "    \"fin_train\": [\"2023-04-25 00:00:00+00:00\", \"2023-04-26 00:00:00+00:00\"],\n",
    "    \"fin_test\": [\"2023-04-26 00:00:00+00:00\"],\n",
    "    \"model_sklearn_name\": [\"ARDRegression\"],\n",
    "    \"n_lags\": [5, 10],\n",
    "    \"n_leads\": [5, 10],\n",
    "    \"X_name_features\": [list(set(df_preprocessed.columns)-set(['y','timestamp','id_device']))],\n",
    "    \"Y_name_features\": [\"y\"],\n",
    "    \"lag_columns\": [list(set(df_preprocessed.columns)-set(['y','timestamp','id_device'])) + [\"y\"]],\n",
    "    \"lead_columns\": [\"y\"],\n",
    "    \"scale_in_preprocessing\": [True],\n",
    "    \"name_time_column\": [\"timestamp\"],\n",
    "    \"save_preprocessing\": [True],\n",
    "    \"path_to_save_model\": [\"paper\"],\n",
    "    \"folder_name_model\": [\"ARDRegression\"],\n",
    "    \"folder_name_time_execution\": [\"execution-time-no-defined\"],\n",
    "    \"folder_name_preprocessed_data\": [\"preprocessed-data-to-use-in-model\"],\n",
    "    \"measure_time\": [True],\n",
    "    \"logger\": [None],\n",
    "    \"kwargs_save_object\": [{\"rename_if_exists\": True}],\n",
    "}\n",
    "\n",
    "hyperparameters_specific_regressor_args = {\n",
    "    \"ARDRegression\": {\n",
    "        \"max_iter\": [200, 300],\n",
    "        \"tol\": [0.001, 0.01],\n",
    "        \"alpha_1\": [1e-06, 1e-05],\n",
    "    }\n",
    "}\n",
    "\n",
    "combinations = generate_combinations(hyperparameters_model_space, hyperparameters_specific_regressor_args)\n",
    "hyperparameters = [combination for combination in combinations]\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate combinations of hyperparameters for preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_combinations(parameter_space):\n",
    "    \"\"\"\n",
    "    Generate and preprocess dataframes with optimized parameter combinations.\n",
    "\n",
    "    This function dynamically generates all possible combinations of preprocessing parameters,\n",
    "    applies the preprocessing to the given dataframe, and yields the resulting dataframes\n",
    "    along with their parameter configurations.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    parameter_space : dict\n",
    "        A dictionary defining the preprocessing parameters and their possible values.\n",
    "        These parameters include:\n",
    "        - `resample_freq` (list of str): Frequencies for resampling the time-series data.\n",
    "        - `aggregation_func` (list of str): Aggregation functions to apply during resampling.\n",
    "        - `interpolation_method` (list of str): Methods to use for interpolating missing values.\n",
    "        - `target_variable` (list of str): Names of the columns to set as the target variable.\n",
    "        - `pivot` (list of bool): Whether to apply a pivot operation.\n",
    "        - `pivot_index` (list of list of str): Columns to use as the index in the pivot table.\n",
    "        - `pivot_columns` (list of list of str): Columns to use as the columns in the pivot table.\n",
    "        - `pivot_values` (list of list of str): Columns to use as the values in the pivot table.\n",
    "        - `subset_cols` (list of list of str): Columns to subset the dataframe to.\n",
    "        - `target_column_name` (list of str): New names for the target variable column.\n",
    "\n",
    "    Yields:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing:\n",
    "        - `parameters`: The parameter configuration used for preprocessing.\n",
    "        - `dataframe`: The resulting preprocessed dataframe.\n",
    "\n",
    "    Example Usage:\n",
    "    --------------\n",
    "    ```python\n",
    "    parameter_space = {\n",
    "        \"resample_freq\": [\"60S\", \"30S\"],\n",
    "        \"aggregation_func\": [\"mean\", \"median\"],\n",
    "        \"interpolation_method\": [\"linear\", \"quadratic\"],\n",
    "        \"target_variable\": [\"00-eco2\"],\n",
    "        \"pivot\": [True, False],\n",
    "        \"pivot_index\": [[\"timestamp\", \"id_device\"]],\n",
    "        \"pivot_columns\": [[\"id_variable\"]],\n",
    "        \"pivot_values\": [[\"value\"]],\n",
    "        \"subset_cols\": [[\"timestamp\", \"id_device\", \"id_variable\", \"value\"]],\n",
    "        \"target_column_name\": [\"y\"]\n",
    "    }\n",
    "\n",
    "    for result in create_dataframe_combinations(parameter_space):\n",
    "        print(result[\"parameters\"])\n",
    "        print(result[\"dataframe\"])\n",
    "    ```\n",
    "    \"\"\"\n",
    "    keys, values = zip(*parameter_space.items())\n",
    "\n",
    "    for combination in product(*values):\n",
    "        params = dict(zip(keys, combination))\n",
    "\n",
    "        # Prepare and preprocess the dataframe\n",
    "        try:\n",
    "            df_preprocessed = preprocess_and_standardize_dataframe(\n",
    "                df=params.get(\"df\"),  # Assume df is passed in the parameter space\n",
    "                resample_freq=params[\"resample_freq\"],\n",
    "                aggregation_func=params[\"aggregation_func\"],\n",
    "                interpolation_method=params[\"interpolation_method\"],\n",
    "                target_variable=params.get(\"target_variable\"),\n",
    "                outlier_cols=params.get(\"outlier_cols\"),\n",
    "                pivot=params[\"pivot\"],\n",
    "                pivot_index=params.get(\"pivot_index\"),\n",
    "                pivot_columns=params.get(\"pivot_columns\"),\n",
    "                pivot_values=params.get(\"pivot_values\"),\n",
    "                subset_cols=params.get(\"subset_cols\"),\n",
    "                target_column_name=params.get(\"target_column_name\"),\n",
    "            )\n",
    "\n",
    "            yield {\n",
    "                \"parameters\": params,\n",
    "                \"dataframe\": df_preprocessed\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing combination {params}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function of cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_utils import get_all_regressors\n",
    "import pandas as pd\n",
    "from PersistenceManager import PersistenceManager\n",
    "from predictions import create_model_machine_learning_algorithm\n",
    "from own_utils import load_json\n",
    "from cleaning import prepare_dataframe_from_db, process_time_series_data\n",
    "from predictions import run_time_series_prediction_pipeline, process_model_machine_learning, evaluate_model\n",
    "from own_utils import execute_concurrently\n",
    "from own_utils import list_directories_by_depth\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rober\\OneDrive\\statistics_hub\\src\\PersistenceManager.py:1014: UserWarning: The specified flag file paper\\ARDRegression\\initrain-2023_4_18_0_0_0-UTC0___fintrain-2023_4_25_0_0_0-UTC0\\execution-time-no-defined\\training-done.txt does not exist.\n",
      "  warnings.warn(f\"The specified flag file {flag_file_path} does not exist.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task with args {'ini_train': '2023-04-18 00:00:00+00:00', 'fin_train': '2023-04-25 00:00:00+00:00', 'fin_test': '2023-04-26 00:00:00+00:00', 'n_lags': 5, 'n_leads': 5, 'X_name_features': ['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp', '02-pres'], 'Y_name_features': 'y', 'lag_columns': ['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp', '02-pres', 'y'], 'lead_columns': 'y', 'scale_in_preprocessing': True, 'name_time_column': 'timestamp', 'save_preprocessing': True, 'path_to_save_model': 'paper', 'folder_name_model': 'ARDRegression', 'folder_name_time_execution': 'execution-time-no-defined', 'folder_name_preprocessed_data': 'preprocessed-data-to-use-in-model', 'measure_time': True, 'logger': None, 'kwargs_save_object': {'rename_if_exists': True}, 'tidy_data':                       timestamp id_device           y    00-temp     01-hum  \\\n",
      "0     2023-04-18 09:31:00+00:00   DBEM003  400.000000  18.570000  33.050000   \n",
      "1     2023-04-18 09:32:00+00:00   DBEM003  400.000000  18.560000  33.000000   \n",
      "2     2023-04-18 09:33:00+00:00   DBEM003  400.000000  18.550000  33.030000   \n",
      "3     2023-04-18 09:34:00+00:00   DBEM003  400.000000  18.530000  33.090000   \n",
      "4     2023-04-18 09:35:00+00:00   DBEM003  400.000000  18.530000  33.050000   \n",
      "...                         ...       ...         ...        ...        ...   \n",
      "32544 2023-05-10 23:55:00+00:00   DBEM003  449.833333  25.281667  29.266667   \n",
      "32545 2023-05-10 23:56:00+00:00   DBEM003  427.000000  25.278333  29.221667   \n",
      "32546 2023-05-10 23:57:00+00:00   DBEM003  414.500000  25.271667  29.205000   \n",
      "32547 2023-05-10 23:58:00+00:00   DBEM003  407.166667  25.268333  29.241667   \n",
      "32548 2023-05-10 23:59:00+00:00   DBEM003  423.000000  25.275000  29.125000   \n",
      "\n",
      "         01-tvoc     02-pres    03-siaq    04-diaq  \n",
      "0       2.000000  934.700000  25.000000  27.000000  \n",
      "1       1.000000  934.720000  25.000000  25.000000  \n",
      "2       8.000000  934.700000  25.000000  25.000000  \n",
      "3       4.000000  934.660000  25.000000  26.000000  \n",
      "4       3.000000  934.680000  26.000000  29.000000  \n",
      "...          ...         ...        ...        ...  \n",
      "32544  38.000000  939.910000  26.166667  26.666667  \n",
      "32545  39.333333  939.913333  27.166667  28.000000  \n",
      "32546  22.333333  939.873333  27.666667  29.000000  \n",
      "32547  16.166667  939.873333  28.833333  30.333333  \n",
      "32548  25.666667  939.843333  28.833333  30.166667  \n",
      "\n",
      "[32549 rows x 9 columns], 'model_sklearn_name': 'ARDRegression', 'metadata_preprocessing': {'resample_freq': '60S', 'aggregation_func': 'mean', 'interpolation_method': 'linear', 'outlier_cols': None}, 'machine_learning_model_args': {'max_iter': 200, 'tol': 0.001, 'alpha_1': 1e-06}} processed successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': MultiOutputRegressor(estimator=ARDRegression(max_iter=200)),\n",
       "  'preprocessing_train': {'preprocess_columns': {'order': 1,\n",
       "    'df':         04-diaq     01-hum   01-tvoc    03-siaq    00-temp     02-pres  \\\n",
       "    0     27.000000  33.050000  2.000000  25.000000  18.570000  934.700000   \n",
       "    1     25.000000  33.000000  1.000000  25.000000  18.560000  934.720000   \n",
       "    2     25.000000  33.030000  8.000000  25.000000  18.550000  934.700000   \n",
       "    3     26.000000  33.090000  4.000000  25.000000  18.530000  934.660000   \n",
       "    4     29.000000  33.050000  3.000000  26.000000  18.530000  934.680000   \n",
       "    ...         ...        ...       ...        ...        ...         ...   \n",
       "    9505  25.833333  32.765000  6.000000  25.166667  24.250000  938.323333   \n",
       "    9506  25.666667  32.758333  2.833333  25.166667  24.250000  938.326667   \n",
       "    9507  25.833333  32.758333  3.166667  25.500000  24.251667  938.323333   \n",
       "    9508  25.166667  32.751667  3.833333  25.000000  24.253333  938.290000   \n",
       "    9509  25.166667  32.755000  3.333333  25.000000  24.251667  938.286667   \n",
       "    \n",
       "                   y  \n",
       "    0     400.000000  \n",
       "    1     400.000000  \n",
       "    2     400.000000  \n",
       "    3     400.000000  \n",
       "    4     400.000000  \n",
       "    ...          ...  \n",
       "    9505  401.833333  \n",
       "    9506  403.500000  \n",
       "    9507  400.000000  \n",
       "    9508  400.000000  \n",
       "    9509  400.333333  \n",
       "    \n",
       "    [9510 rows x 7 columns],\n",
       "    'transformer': PreprocessColumns(X_name_features=['04-diaq', '01-hum', '01-tvoc', '03-siaq',\n",
       "                                       '00-temp', '02-pres'],\n",
       "                      Y_name_features=['y']),\n",
       "    'execution_time_in_seconds': 0.0011408329010009766},\n",
       "   'preprocess_scaler': {'order': 2,\n",
       "    'df':      04-diaq 01-hum 01-tvoc 03-siaq 00-temp 02-pres    y\n",
       "    0        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    1        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    2        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    3        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    4        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    ...      ...    ...     ...     ...     ...     ...  ...\n",
       "    9505     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    9506     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    9507     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    9508     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    9509     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    \n",
       "    [9510 rows x 7 columns],\n",
       "    'transformer': PreprocessScaler(),\n",
       "    'execution_time_in_seconds': 0.010384559631347656},\n",
       "   'preprocess_lags': {'order': 3,\n",
       "    'df':        04-diaq    01-hum   01-tvoc   03-siaq   00-temp   02-pres         y  \\\n",
       "    0    -0.820029  1.413087 -1.665305 -0.704419 -7.221929  0.400785 -0.792509   \n",
       "    1    -0.849725  1.385378 -1.690257 -0.704419 -7.235410  0.406584 -0.792509   \n",
       "    2    -0.849725  1.402003 -1.515595 -0.704419 -7.248892  0.400785 -0.792509   \n",
       "    3    -0.834877  1.435254 -1.615402 -0.704419 -7.275855  0.389185 -0.792509   \n",
       "    4    -0.790334  1.413087 -1.640354 -0.686576 -7.275855  0.394985 -0.792509   \n",
       "    ...        ...       ...       ...       ...       ...       ...       ...   \n",
       "    9505 -0.837352  1.255145 -1.565498 -0.701445  0.435604  1.451488 -0.779815   \n",
       "    9506 -0.839826  1.251451 -1.644512 -0.701445  0.435604  1.452455 -0.768275   \n",
       "    9507 -0.837352  1.251451 -1.636195 -0.695497  0.437851  1.451488 -0.792509   \n",
       "    9508 -0.847250  1.247756 -1.619560 -0.704419  0.440098  1.441822 -0.792509   \n",
       "    9509 -0.847250  1.249603 -1.632036 -0.704419  0.437851  1.440855 -0.790201   \n",
       "    \n",
       "          lag_04-diaq_1  lag_04-diaq_2  lag_04-diaq_3  ...  lag_02-pres_1  \\\n",
       "    0          0.000089       0.000178       0.000266  ...      -0.000152   \n",
       "    1         -0.820029       0.000178       0.000266  ...       0.400785   \n",
       "    2         -0.849725      -0.820029       0.000266  ...       0.406584   \n",
       "    3         -0.849725      -0.849725      -0.820029  ...       0.400785   \n",
       "    4         -0.834877      -0.849725      -0.849725  ...       0.389185   \n",
       "    ...             ...            ...            ...  ...            ...   \n",
       "    9505      -0.847250      -0.842301      -0.847250  ...       1.454388   \n",
       "    9506      -0.837352      -0.847250      -0.842301  ...       1.451488   \n",
       "    9507      -0.839826      -0.837352      -0.847250  ...       1.452455   \n",
       "    9508      -0.837352      -0.839826      -0.837352  ...       1.451488   \n",
       "    9509      -0.847250      -0.837352      -0.839826  ...       1.441822   \n",
       "    \n",
       "          lag_02-pres_2  lag_02-pres_3  lag_02-pres_4  lag_02-pres_5   lag_y_1  \\\n",
       "    0         -0.000303      -0.000456      -0.000609      -0.000762  0.000083   \n",
       "    1         -0.000303      -0.000456      -0.000609      -0.000762 -0.792509   \n",
       "    2          0.400785      -0.000456      -0.000609      -0.000762 -0.792509   \n",
       "    3          0.406584       0.400785      -0.000609      -0.000762 -0.792509   \n",
       "    4          0.400785       0.406584       0.400785      -0.000762 -0.792509   \n",
       "    ...             ...            ...            ...            ...       ...   \n",
       "    9505       1.449555       1.443755       1.443755       1.443755 -0.787893   \n",
       "    9506       1.454388       1.449555       1.443755       1.443755 -0.779815   \n",
       "    9507       1.451488       1.454388       1.449555       1.443755 -0.768275   \n",
       "    9508       1.452455       1.451488       1.454388       1.449555 -0.792509   \n",
       "    9509       1.451488       1.452455       1.451488       1.454388 -0.792509   \n",
       "    \n",
       "           lag_y_2   lag_y_3   lag_y_4   lag_y_5  \n",
       "    0     0.000166  0.000250  0.000331  0.000413  \n",
       "    1     0.000166  0.000250  0.000331  0.000413  \n",
       "    2    -0.792509  0.000250  0.000331  0.000413  \n",
       "    3    -0.792509 -0.792509  0.000331  0.000413  \n",
       "    4    -0.792509 -0.792509 -0.792509  0.000413  \n",
       "    ...        ...       ...       ...       ...  \n",
       "    9505 -0.792509 -0.789047 -0.792509 -0.764813  \n",
       "    9506 -0.787893 -0.792509 -0.789047 -0.792509  \n",
       "    9507 -0.779815 -0.787893 -0.792509 -0.789047  \n",
       "    9508 -0.768275 -0.779815 -0.787893 -0.792509  \n",
       "    9509 -0.792509 -0.768275 -0.779815 -0.787893  \n",
       "    \n",
       "    [9510 rows x 42 columns],\n",
       "    'transformer': PreprocessLags(columns=['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp',\n",
       "                            '02-pres', 'y'],\n",
       "                   n=5),\n",
       "    'execution_time_in_seconds': 0.008999824523925781},\n",
       "   'preprocess_leads': {'order': 4,\n",
       "    'df':        04-diaq    01-hum   01-tvoc   03-siaq   00-temp   02-pres         y  \\\n",
       "    0    -0.820029  1.413087 -1.665305 -0.704419 -7.221929  0.400785 -0.792509   \n",
       "    1    -0.849725  1.385378 -1.690257 -0.704419 -7.235410  0.406584 -0.792509   \n",
       "    2    -0.849725  1.402003 -1.515595 -0.704419 -7.248892  0.400785 -0.792509   \n",
       "    3    -0.834877  1.435254 -1.615402 -0.704419 -7.275855  0.389185 -0.792509   \n",
       "    4    -0.790334  1.413087 -1.640354 -0.686576 -7.275855  0.394985 -0.792509   \n",
       "    ...        ...       ...       ...       ...       ...       ...       ...   \n",
       "    9505 -0.837352  1.255145 -1.565498 -0.701445  0.435604  1.451488 -0.779815   \n",
       "    9506 -0.839826  1.251451 -1.644512 -0.701445  0.435604  1.452455 -0.768275   \n",
       "    9507 -0.837352  1.251451 -1.636195 -0.695497  0.437851  1.451488 -0.792509   \n",
       "    9508 -0.847250  1.247756 -1.619560 -0.704419  0.440098  1.441822 -0.792509   \n",
       "    9509 -0.847250  1.249603 -1.632036 -0.704419  0.437851  1.440855 -0.790201   \n",
       "    \n",
       "          lag_04-diaq_1  lag_04-diaq_2  lag_04-diaq_3  ...   lag_y_1   lag_y_2  \\\n",
       "    0          0.000089       0.000178       0.000266  ...  0.000083  0.000166   \n",
       "    1         -0.820029       0.000178       0.000266  ... -0.792509  0.000166   \n",
       "    2         -0.849725      -0.820029       0.000266  ... -0.792509 -0.792509   \n",
       "    3         -0.849725      -0.849725      -0.820029  ... -0.792509 -0.792509   \n",
       "    4         -0.834877      -0.849725      -0.849725  ... -0.792509 -0.792509   \n",
       "    ...             ...            ...            ...  ...       ...       ...   \n",
       "    9505      -0.847250      -0.842301      -0.847250  ... -0.787893 -0.792509   \n",
       "    9506      -0.837352      -0.847250      -0.842301  ... -0.779815 -0.787893   \n",
       "    9507      -0.839826      -0.837352      -0.847250  ... -0.768275 -0.779815   \n",
       "    9508      -0.837352      -0.839826      -0.837352  ... -0.792509 -0.768275   \n",
       "    9509      -0.847250      -0.837352      -0.839826  ... -0.792509 -0.792509   \n",
       "    \n",
       "           lag_y_3   lag_y_4   lag_y_5  lead_y_1  lead_y_2  lead_y_3  lead_y_4  \\\n",
       "    0     0.000250  0.000331  0.000413 -0.792509 -0.792509 -0.792509 -0.792509   \n",
       "    1     0.000250  0.000331  0.000413 -0.792509 -0.792509 -0.792509 -0.792509   \n",
       "    2     0.000250  0.000331  0.000413 -0.792509 -0.792509 -0.792509 -0.792509   \n",
       "    3    -0.792509  0.000331  0.000413 -0.792509 -0.792509 -0.792509 -0.792509   \n",
       "    4    -0.792509 -0.792509  0.000413 -0.792509 -0.792509 -0.792509 -0.792509   \n",
       "    ...        ...       ...       ...       ...       ...       ...       ...   \n",
       "    9505 -0.789047 -0.792509 -0.764813 -0.768275 -0.792509 -0.792509 -0.790201   \n",
       "    9506 -0.792509 -0.789047 -0.792509 -0.792509 -0.792509 -0.790201  0.000333   \n",
       "    9507 -0.787893 -0.792509 -0.789047 -0.792509 -0.790201  0.000250  0.000333   \n",
       "    9508 -0.779815 -0.787893 -0.792509 -0.790201  0.000167  0.000250  0.000333   \n",
       "    9509 -0.768275 -0.779815 -0.787893  0.000083  0.000167  0.000250  0.000333   \n",
       "    \n",
       "          lead_y_5  \n",
       "    0    -0.792509  \n",
       "    1    -0.792509  \n",
       "    2    -0.792509  \n",
       "    3    -0.792509  \n",
       "    4    -0.792509  \n",
       "    ...        ...  \n",
       "    9505  0.000417  \n",
       "    9506  0.000417  \n",
       "    9507  0.000417  \n",
       "    9508  0.000417  \n",
       "    9509  0.000417  \n",
       "    \n",
       "    [9510 rows x 47 columns],\n",
       "    'transformer': PreprocessLeads(columns=['y'], n=5),\n",
       "    'execution_time_in_seconds': 0.003008604049682617}},\n",
       "  'preprocessing_test': {'preprocess_columns': {'order': 1,\n",
       "    'df':         04-diaq     01-hum    01-tvoc    03-siaq    00-temp     02-pres  \\\n",
       "    0     25.666667  32.751667   2.000000  25.333333  24.256667  938.286667   \n",
       "    1     25.333333  32.748333  10.666667  25.000000  24.260000  938.270000   \n",
       "    2     25.000000  32.755000   4.333333  25.000000  24.258333  938.270000   \n",
       "    3     25.666667  32.760000  13.833333  25.333333  24.256667  938.263333   \n",
       "    4     25.200000  32.764000   5.800000  25.200000  24.260000  938.246000   \n",
       "    ...         ...        ...        ...        ...        ...         ...   \n",
       "    1435  28.500000  33.310000  42.333333  27.500000  24.586667  937.633333   \n",
       "    1436  28.166667  33.293333  43.833333  27.333333  24.596667  937.646667   \n",
       "    1437  26.833333  33.295000  41.500000  26.166667  24.595000  937.663333   \n",
       "    1438  26.833333  33.303333  42.833333  26.333333  24.595000  937.683333   \n",
       "    1439  25.833333  33.298333  41.833333  25.666667  24.591667  937.670000   \n",
       "    \n",
       "                   y  \n",
       "    0     400.666667  \n",
       "    1     404.666667  \n",
       "    2     400.000000  \n",
       "    3     401.000000  \n",
       "    4     400.000000  \n",
       "    ...          ...  \n",
       "    1435  412.666667  \n",
       "    1436  414.333333  \n",
       "    1437  410.166667  \n",
       "    1438  408.000000  \n",
       "    1439  408.833333  \n",
       "    \n",
       "    [1440 rows x 7 columns],\n",
       "    'transformer': PreprocessColumns(X_name_features=['04-diaq', '01-hum', '01-tvoc', '03-siaq',\n",
       "                                       '00-temp', '02-pres'],\n",
       "                      Y_name_features=['y']),\n",
       "    'execution_time_in_seconds': 0.0009911060333251953},\n",
       "   'preprocess_scaler': {'order': 2,\n",
       "    'df':      04-diaq 01-hum 01-tvoc 03-siaq 00-temp 02-pres    y\n",
       "    0        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    1        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    2        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    3        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    4        NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    ...      ...    ...     ...     ...     ...     ...  ...\n",
       "    1435     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    1436     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    1437     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    1438     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    1439     NaN    NaN     NaN     NaN     NaN     NaN  NaN\n",
       "    \n",
       "    [1440 rows x 7 columns],\n",
       "    'transformer': PreprocessScaler(),\n",
       "    'execution_time_in_seconds': 0.008004903793334961},\n",
       "   'preprocess_lags': {'order': 3,\n",
       "    'df':        04-diaq    01-hum   01-tvoc   03-siaq   00-temp   02-pres         y  \\\n",
       "    0    -0.717129 -1.760529 -1.362757 -0.696208 -1.505240  1.229977 -0.489879   \n",
       "    1    -0.721754 -1.766078 -1.111761 -0.700804 -1.477474  1.210974 -0.459379   \n",
       "    2    -0.726380 -1.754981 -1.295181 -0.700804 -1.491357  1.210974 -0.494963   \n",
       "    3    -0.717129 -1.746658 -1.020051 -0.696208 -1.505240  1.203373 -0.487338   \n",
       "    4    -0.723605 -1.740000 -1.252705 -0.698046 -1.477474  1.183611 -0.494963   \n",
       "    ...        ...       ...       ...       ...       ...       ...       ...   \n",
       "    1435 -0.677815 -0.831140 -0.194661 -0.666335  1.243666  0.485085 -0.398378   \n",
       "    1436 -0.682440 -0.858883 -0.151220 -0.668633  1.326966  0.500287 -0.385670   \n",
       "    1437 -0.700941 -0.856108 -0.218796 -0.684719  1.313083  0.519289 -0.417441   \n",
       "    1438 -0.700941 -0.842237 -0.180181 -0.682421  1.313083  0.542092 -0.433962   \n",
       "    1439 -0.714817 -0.850560 -0.209142 -0.691612  1.285316  0.526890 -0.427608   \n",
       "    \n",
       "          lag_04-diaq_1  lag_04-diaq_2  lag_04-diaq_3  ...  lag_02-pres_1  \\\n",
       "    0          0.000497       0.000985       0.001473  ...      -0.000366   \n",
       "    1         -0.717129       0.000985       0.001473  ...       1.229977   \n",
       "    2         -0.721754      -0.717129       0.001473  ...       1.210974   \n",
       "    3         -0.726380      -0.721754      -0.717129  ...       1.210974   \n",
       "    4         -0.717129      -0.726380      -0.721754  ...       1.203373   \n",
       "    ...             ...            ...            ...  ...            ...   \n",
       "    1435      -0.691690      -0.682440      -0.684752  ...       0.458482   \n",
       "    1436      -0.677815      -0.691690      -0.682440  ...       0.485085   \n",
       "    1437      -0.682440      -0.677815      -0.691690  ...       0.500287   \n",
       "    1438      -0.700941      -0.682440      -0.677815  ...       0.519289   \n",
       "    1439      -0.700941      -0.700941      -0.682440  ...       0.542092   \n",
       "    \n",
       "          lag_02-pres_2  lag_02-pres_3  lag_02-pres_4  lag_02-pres_5   lag_y_1  \\\n",
       "    0         -0.000743      -0.001105      -0.001454      -0.001793  0.000297   \n",
       "    1         -0.000743      -0.001105      -0.001454      -0.001793 -0.489879   \n",
       "    2          1.229977      -0.001105      -0.001454      -0.001793 -0.459379   \n",
       "    3          1.210974       1.229977      -0.001454      -0.001793 -0.494963   \n",
       "    4          1.210974       1.210974       1.229977      -0.001793 -0.487338   \n",
       "    ...             ...            ...            ...            ...       ...   \n",
       "    1435       0.473684       0.488885       0.504087       0.504087 -0.409816   \n",
       "    1436       0.458482       0.473684       0.488885       0.504087 -0.398378   \n",
       "    1437       0.485085       0.458482       0.473684       0.488885 -0.385670   \n",
       "    1438       0.500287       0.485085       0.458482       0.473684 -0.417441   \n",
       "    1439       0.519289       0.500287       0.485085       0.458482 -0.433962   \n",
       "    \n",
       "           lag_y_2   lag_y_3   lag_y_4   lag_y_5  \n",
       "    0     0.000599  0.000890  0.001159  0.001438  \n",
       "    1     0.000599  0.000890  0.001159  0.001438  \n",
       "    2    -0.489879  0.000890  0.001159  0.001438  \n",
       "    3    -0.459379 -0.489879  0.001159  0.001438  \n",
       "    4    -0.494963 -0.459379 -0.489879  0.001438  \n",
       "    ...        ...       ...       ...       ...  \n",
       "    1435 -0.369149 -0.412358 -0.433962 -0.461921  \n",
       "    1436 -0.409816 -0.369149 -0.412358 -0.433962  \n",
       "    1437 -0.398378 -0.409816 -0.369149 -0.412358  \n",
       "    1438 -0.385670 -0.398378 -0.409816 -0.369149  \n",
       "    1439 -0.417441 -0.385670 -0.398378 -0.409816  \n",
       "    \n",
       "    [1440 rows x 42 columns],\n",
       "    'transformer': PreprocessLags(columns=['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp',\n",
       "                            '02-pres', 'y'],\n",
       "                   n=5),\n",
       "    'execution_time_in_seconds': 0.007993459701538086},\n",
       "   'preprocess_leads': {'order': 4,\n",
       "    'df':        04-diaq    01-hum   01-tvoc   03-siaq   00-temp   02-pres         y  \\\n",
       "    0    -0.717129 -1.760529 -1.362757 -0.696208 -1.505240  1.229977 -0.489879   \n",
       "    1    -0.721754 -1.766078 -1.111761 -0.700804 -1.477474  1.210974 -0.459379   \n",
       "    2    -0.726380 -1.754981 -1.295181 -0.700804 -1.491357  1.210974 -0.494963   \n",
       "    3    -0.717129 -1.746658 -1.020051 -0.696208 -1.505240  1.203373 -0.487338   \n",
       "    4    -0.723605 -1.740000 -1.252705 -0.698046 -1.477474  1.183611 -0.494963   \n",
       "    ...        ...       ...       ...       ...       ...       ...       ...   \n",
       "    1435 -0.677815 -0.831140 -0.194661 -0.666335  1.243666  0.485085 -0.398378   \n",
       "    1436 -0.682440 -0.858883 -0.151220 -0.668633  1.326966  0.500287 -0.385670   \n",
       "    1437 -0.700941 -0.856108 -0.218796 -0.684719  1.313083  0.519289 -0.417441   \n",
       "    1438 -0.700941 -0.842237 -0.180181 -0.682421  1.313083  0.542092 -0.433962   \n",
       "    1439 -0.714817 -0.850560 -0.209142 -0.691612  1.285316  0.526890 -0.427608   \n",
       "    \n",
       "          lag_04-diaq_1  lag_04-diaq_2  lag_04-diaq_3  ...   lag_y_1   lag_y_2  \\\n",
       "    0          0.000497       0.000985       0.001473  ...  0.000297  0.000599   \n",
       "    1         -0.717129       0.000985       0.001473  ... -0.489879  0.000599   \n",
       "    2         -0.721754      -0.717129       0.001473  ... -0.459379 -0.489879   \n",
       "    3         -0.726380      -0.721754      -0.717129  ... -0.494963 -0.459379   \n",
       "    4         -0.717129      -0.726380      -0.721754  ... -0.487338 -0.494963   \n",
       "    ...             ...            ...            ...  ...       ...       ...   \n",
       "    1435      -0.691690      -0.682440      -0.684752  ... -0.409816 -0.369149   \n",
       "    1436      -0.677815      -0.691690      -0.682440  ... -0.398378 -0.409816   \n",
       "    1437      -0.682440      -0.677815      -0.691690  ... -0.385670 -0.398378   \n",
       "    1438      -0.700941      -0.682440      -0.677815  ... -0.417441 -0.385670   \n",
       "    1439      -0.700941      -0.700941      -0.682440  ... -0.433962 -0.417441   \n",
       "    \n",
       "           lag_y_3   lag_y_4   lag_y_5  lead_y_1  lead_y_2  lead_y_3  lead_y_4  \\\n",
       "    0     0.000890  0.001159  0.001438 -0.459379 -0.494963 -0.487338 -0.494963   \n",
       "    1     0.000890  0.001159  0.001438 -0.494963 -0.487338 -0.494963 -0.494963   \n",
       "    2     0.000890  0.001159  0.001438 -0.487338 -0.494963 -0.494963 -0.419983   \n",
       "    3    -0.489879  0.001159  0.001438 -0.494963 -0.494963 -0.419983 -0.493692   \n",
       "    4    -0.459379 -0.489879  0.001438 -0.494963 -0.419983 -0.493692 -0.486067   \n",
       "    ...        ...       ...       ...       ...       ...       ...       ...   \n",
       "    1435 -0.412358 -0.433962 -0.461921 -0.385670 -0.417441 -0.433962 -0.427608   \n",
       "    1436 -0.369149 -0.412358 -0.433962 -0.417441 -0.433962 -0.427608  0.001345   \n",
       "    1437 -0.409816 -0.369149 -0.412358 -0.433962 -0.427608  0.001005  0.001345   \n",
       "    1438 -0.398378 -0.409816 -0.369149 -0.427608  0.000660  0.001005  0.001345   \n",
       "    1439 -0.385670 -0.398378 -0.409816  0.000340  0.000660  0.001005  0.001345   \n",
       "    \n",
       "          lead_y_5  \n",
       "    0    -0.494963  \n",
       "    1    -0.419983  \n",
       "    2    -0.493692  \n",
       "    3    -0.486067  \n",
       "    4    -0.494963  \n",
       "    ...        ...  \n",
       "    1435  0.001691  \n",
       "    1436  0.001691  \n",
       "    1437  0.001691  \n",
       "    1438  0.001691  \n",
       "    1439  0.001691  \n",
       "    \n",
       "    [1440 rows x 47 columns],\n",
       "    'transformer': PreprocessLeads(columns=['y'], n=5),\n",
       "    'execution_time_in_seconds': 0.0010137557983398438}},\n",
       "  'df_train_X':        04-diaq    01-hum   01-tvoc   03-siaq   00-temp   02-pres  \\\n",
       "  0    -0.820029  1.413087 -1.665305 -0.704419 -7.221929  0.400785   \n",
       "  1    -0.849725  1.385378 -1.690257 -0.704419 -7.235410  0.406584   \n",
       "  2    -0.849725  1.402003 -1.515595 -0.704419 -7.248892  0.400785   \n",
       "  3    -0.834877  1.435254 -1.615402 -0.704419 -7.275855  0.389185   \n",
       "  4    -0.790334  1.413087 -1.640354 -0.686576 -7.275855  0.394985   \n",
       "  ...        ...       ...       ...       ...       ...       ...   \n",
       "  9505 -0.837352  1.255145 -1.565498 -0.701445  0.435604  1.451488   \n",
       "  9506 -0.839826  1.251451 -1.644512 -0.701445  0.435604  1.452455   \n",
       "  9507 -0.837352  1.251451 -1.636195 -0.695497  0.437851  1.451488   \n",
       "  9508 -0.847250  1.247756 -1.619560 -0.704419  0.440098  1.441822   \n",
       "  9509 -0.847250  1.249603 -1.632036 -0.704419  0.437851  1.440855   \n",
       "  \n",
       "        lag_04-diaq_1  lag_04-diaq_2  lag_04-diaq_3  lag_04-diaq_4  ...  \\\n",
       "  0          0.000089       0.000178       0.000266       0.000355  ...   \n",
       "  1         -0.820029       0.000178       0.000266       0.000355  ...   \n",
       "  2         -0.849725      -0.820029       0.000266       0.000355  ...   \n",
       "  3         -0.849725      -0.849725      -0.820029       0.000355  ...   \n",
       "  4         -0.834877      -0.849725      -0.849725      -0.820029  ...   \n",
       "  ...             ...            ...            ...            ...  ...   \n",
       "  9505      -0.847250      -0.842301      -0.847250      -0.844776  ...   \n",
       "  9506      -0.837352      -0.847250      -0.842301      -0.847250  ...   \n",
       "  9507      -0.839826      -0.837352      -0.847250      -0.842301  ...   \n",
       "  9508      -0.837352      -0.839826      -0.837352      -0.847250  ...   \n",
       "  9509      -0.847250      -0.837352      -0.839826      -0.837352  ...   \n",
       "  \n",
       "        lag_02-pres_2  lag_02-pres_3  lag_02-pres_4  lag_02-pres_5         y  \\\n",
       "  0         -0.000303      -0.000456      -0.000609      -0.000762 -0.792509   \n",
       "  1         -0.000303      -0.000456      -0.000609      -0.000762 -0.792509   \n",
       "  2          0.400785      -0.000456      -0.000609      -0.000762 -0.792509   \n",
       "  3          0.406584       0.400785      -0.000609      -0.000762 -0.792509   \n",
       "  4          0.400785       0.406584       0.400785      -0.000762 -0.792509   \n",
       "  ...             ...            ...            ...            ...       ...   \n",
       "  9505       1.449555       1.443755       1.443755       1.443755 -0.779815   \n",
       "  9506       1.454388       1.449555       1.443755       1.443755 -0.768275   \n",
       "  9507       1.451488       1.454388       1.449555       1.443755 -0.792509   \n",
       "  9508       1.452455       1.451488       1.454388       1.449555 -0.792509   \n",
       "  9509       1.451488       1.452455       1.451488       1.454388 -0.790201   \n",
       "  \n",
       "         lag_y_1   lag_y_2   lag_y_3   lag_y_4   lag_y_5  \n",
       "  0     0.000083  0.000166  0.000250  0.000331  0.000413  \n",
       "  1    -0.792509  0.000166  0.000250  0.000331  0.000413  \n",
       "  2    -0.792509 -0.792509  0.000250  0.000331  0.000413  \n",
       "  3    -0.792509 -0.792509 -0.792509  0.000331  0.000413  \n",
       "  4    -0.792509 -0.792509 -0.792509 -0.792509  0.000413  \n",
       "  ...        ...       ...       ...       ...       ...  \n",
       "  9505 -0.787893 -0.792509 -0.789047 -0.792509 -0.764813  \n",
       "  9506 -0.779815 -0.787893 -0.792509 -0.789047 -0.792509  \n",
       "  9507 -0.768275 -0.779815 -0.787893 -0.792509 -0.789047  \n",
       "  9508 -0.792509 -0.768275 -0.779815 -0.787893 -0.792509  \n",
       "  9509 -0.792509 -0.792509 -0.768275 -0.779815 -0.787893  \n",
       "  \n",
       "  [9510 rows x 42 columns],\n",
       "  'df_test_X':        04-diaq    01-hum   01-tvoc   03-siaq   00-temp   02-pres  \\\n",
       "  0    -0.717129 -1.760529 -1.362757 -0.696208 -1.505240  1.229977   \n",
       "  1    -0.721754 -1.766078 -1.111761 -0.700804 -1.477474  1.210974   \n",
       "  2    -0.726380 -1.754981 -1.295181 -0.700804 -1.491357  1.210974   \n",
       "  3    -0.717129 -1.746658 -1.020051 -0.696208 -1.505240  1.203373   \n",
       "  4    -0.723605 -1.740000 -1.252705 -0.698046 -1.477474  1.183611   \n",
       "  ...        ...       ...       ...       ...       ...       ...   \n",
       "  1435 -0.677815 -0.831140 -0.194661 -0.666335  1.243666  0.485085   \n",
       "  1436 -0.682440 -0.858883 -0.151220 -0.668633  1.326966  0.500287   \n",
       "  1437 -0.700941 -0.856108 -0.218796 -0.684719  1.313083  0.519289   \n",
       "  1438 -0.700941 -0.842237 -0.180181 -0.682421  1.313083  0.542092   \n",
       "  1439 -0.714817 -0.850560 -0.209142 -0.691612  1.285316  0.526890   \n",
       "  \n",
       "        lag_04-diaq_1  lag_04-diaq_2  lag_04-diaq_3  lag_04-diaq_4  ...  \\\n",
       "  0          0.000497       0.000985       0.001473       0.001949  ...   \n",
       "  1         -0.717129       0.000985       0.001473       0.001949  ...   \n",
       "  2         -0.721754      -0.717129       0.001473       0.001949  ...   \n",
       "  3         -0.726380      -0.721754      -0.717129       0.001949  ...   \n",
       "  4         -0.717129      -0.726380      -0.721754      -0.717129  ...   \n",
       "  ...             ...            ...            ...            ...  ...   \n",
       "  1435      -0.691690      -0.682440      -0.684752      -0.687065  ...   \n",
       "  1436      -0.677815      -0.691690      -0.682440      -0.684752  ...   \n",
       "  1437      -0.682440      -0.677815      -0.691690      -0.682440  ...   \n",
       "  1438      -0.700941      -0.682440      -0.677815      -0.691690  ...   \n",
       "  1439      -0.700941      -0.700941      -0.682440      -0.677815  ...   \n",
       "  \n",
       "        lag_02-pres_2  lag_02-pres_3  lag_02-pres_4  lag_02-pres_5         y  \\\n",
       "  0         -0.000743      -0.001105      -0.001454      -0.001793 -0.489879   \n",
       "  1         -0.000743      -0.001105      -0.001454      -0.001793 -0.459379   \n",
       "  2          1.229977      -0.001105      -0.001454      -0.001793 -0.494963   \n",
       "  3          1.210974       1.229977      -0.001454      -0.001793 -0.487338   \n",
       "  4          1.210974       1.210974       1.229977      -0.001793 -0.494963   \n",
       "  ...             ...            ...            ...            ...       ...   \n",
       "  1435       0.473684       0.488885       0.504087       0.504087 -0.398378   \n",
       "  1436       0.458482       0.473684       0.488885       0.504087 -0.385670   \n",
       "  1437       0.485085       0.458482       0.473684       0.488885 -0.417441   \n",
       "  1438       0.500287       0.485085       0.458482       0.473684 -0.433962   \n",
       "  1439       0.519289       0.500287       0.485085       0.458482 -0.427608   \n",
       "  \n",
       "         lag_y_1   lag_y_2   lag_y_3   lag_y_4   lag_y_5  \n",
       "  0     0.000297  0.000599  0.000890  0.001159  0.001438  \n",
       "  1    -0.489879  0.000599  0.000890  0.001159  0.001438  \n",
       "  2    -0.459379 -0.489879  0.000890  0.001159  0.001438  \n",
       "  3    -0.494963 -0.459379 -0.489879  0.001159  0.001438  \n",
       "  4    -0.487338 -0.494963 -0.459379 -0.489879  0.001438  \n",
       "  ...        ...       ...       ...       ...       ...  \n",
       "  1435 -0.409816 -0.369149 -0.412358 -0.433962 -0.461921  \n",
       "  1436 -0.398378 -0.409816 -0.369149 -0.412358 -0.433962  \n",
       "  1437 -0.385670 -0.398378 -0.409816 -0.369149 -0.412358  \n",
       "  1438 -0.417441 -0.385670 -0.398378 -0.409816 -0.369149  \n",
       "  1439 -0.433962 -0.417441 -0.385670 -0.398378 -0.409816  \n",
       "  \n",
       "  [1440 rows x 42 columns],\n",
       "  'scaler': PreprocessScaler(),\n",
       "  'execution_times': {'execution_times': {'preprocessing_test': {'total': 0.01900196075439453,\n",
       "     'details': {'preprocess_columns': 0.0009911060333251953,\n",
       "      'preprocess_scaler': 0.008004903793334961,\n",
       "      'preprocess_lags': 0.007993459701538086,\n",
       "      'preprocess_leads': 0.0010137557983398438}},\n",
       "    'training': 0.342609167098999}}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_and_standardize_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    resample_freq: str,\n",
    "    aggregation_func: str,\n",
    "    interpolation_method: str,\n",
    "    target_variable: str,\n",
    "    outlier_cols: list = None,\n",
    "    pivot: bool = False,\n",
    "    pivot_index: list = None,\n",
    "    pivot_columns: list = None,\n",
    "    pivot_values: list = None,\n",
    "    subset_cols: list = None,\n",
    "    target_column_name: str = \"y\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess and standardize a dataframe for cross-validation.\n",
    "\n",
    "    This function processes time-series data by resampling, aggregating, and interpolating missing values.\n",
    "    Optionally, it applies a pivot operation to reshape the dataframe into a standardized format.\n",
    "    The target variable can be renamed, and metadata regarding preprocessing is returned for traceability.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to preprocess and standardize.\n",
    "    resample_freq : str\n",
    "        Frequency for resampling the time-series data, following Pandas offset aliases (e.g., '60S', '1H', '1D').\n",
    "    aggregation_func : str\n",
    "        Aggregation function to apply during resampling (e.g., 'mean', 'sum', 'min', 'max').\n",
    "    interpolation_method : str\n",
    "        Method to use for interpolating missing values (e.g., 'linear', 'nearest', 'spline').\n",
    "    target_variable : str\n",
    "        The name of the column to set as the target variable.\n",
    "    outlier_cols : list, optional\n",
    "        List of columns to apply outlier handling. If None, no outlier handling is applied (default is None).\n",
    "    pivot : bool, optional\n",
    "        Whether to apply a pivot operation to the dataframe (default is False).\n",
    "    pivot_index : list, optional\n",
    "        Columns to use as the index in the pivot table (required if `pivot=True`).\n",
    "    pivot_columns : list, optional\n",
    "        Columns to use as the columns in the pivot table (required if `pivot=True`).\n",
    "    pivot_values : list, optional\n",
    "        Columns to use as the values in the pivot table (required if `pivot=True`).\n",
    "    subset_cols : list, optional\n",
    "        List of columns to subset from the dataframe before pivoting (default is None, no subsetting applied).\n",
    "    target_column_name : str, optional\n",
    "        The new name for the target variable column in the standardized dataframe (default is \"y\").\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing:\n",
    "        - 'df_resampled_interpolated' (pd.DataFrame): The preprocessed and standardized dataframe ready for further analysis or modeling.\n",
    "        - 'metadata_preprocessing' (dict): Metadata describing the preprocessing steps, including resampling frequency, aggregation function, \n",
    "          interpolation method, and outlier-handling columns.\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    ValueError\n",
    "        If `pivot=True` but `pivot_index`, `pivot_columns`, or `pivot_values` are not provided.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    ```python\n",
    "    df_preprocessed = preprocess_and_standardize_dataframe(\n",
    "        df=my_df,\n",
    "        resample_freq=\"60S\",\n",
    "        aggregation_func=\"mean\",\n",
    "        interpolation_method=\"linear\",\n",
    "        target_variable=\"00-eco2\",\n",
    "        outlier_cols=[\"value\", \"sensor_reading\"],\n",
    "        pivot=True,\n",
    "        pivot_index=[\"timestamp\", \"id_device\"],\n",
    "        pivot_columns=[\"id_variable\"],\n",
    "        pivot_values=[\"value\"],\n",
    "        subset_cols=[\"timestamp\", \"id_device\", \"id_variable\", \"value\"]\n",
    "    )\n",
    "\n",
    "    # Access preprocessed dataframe\n",
    "    df_processed = df_preprocessed[\"df_resampled_interpolated\"]\n",
    "\n",
    "    # Access metadata on preprocessing steps\n",
    "    metadata = df_preprocessed[\"metadata_preprocessing\"]\n",
    "    ```\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The pivot operation can be useful for transforming long-format data into a wide format for machine learning models.\n",
    "    - Handling of outliers can be customized by specifying the columns where outlier handling should be applied.\n",
    "    - The metadata returned in `metadata_preprocessing` can be useful for debugging and tracking the preprocessing steps applied.\n",
    "    - Ensure that the target variable exists in the dataframe before renaming it with `target_column_name`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Process time-series data: resample, aggregate, and interpolate\n",
    "    df_resampled_interpolated = process_time_series_data(\n",
    "        df=df,\n",
    "        resample_freq=resample_freq,\n",
    "        aggregation_func=aggregation_func,\n",
    "        method=interpolation_method,\n",
    "        outlier_cols=outlier_cols,\n",
    "    )\n",
    "\n",
    "    # Apply pivot operation if required\n",
    "    if pivot:\n",
    "        if not pivot_index or not pivot_columns or not pivot_values:\n",
    "            raise ValueError(\"`pivot_index`, `pivot_columns`, and `pivot_values` must be provided if `pivot=True`.\")\n",
    "        \n",
    "        df_resampled_interpolated = pd.pivot_table(\n",
    "            df_resampled_interpolated.reset_index()[subset_cols],\n",
    "            index=pivot_index,\n",
    "            columns=pivot_columns,\n",
    "            values=pivot_values\n",
    "        ).reset_index()\n",
    "\n",
    "        # Flatten column hierarchy if created by pivot_table\n",
    "        df_resampled_interpolated.columns = [\n",
    "            col[0] if col[-1] == '' else col[-1]\n",
    "            for col in df_resampled_interpolated.columns.to_flat_index()\n",
    "        ]\n",
    "\n",
    "    # Rename target variable column if specified\n",
    "    if target_variable:\n",
    "        df_resampled_interpolated.rename(columns={target_variable: target_column_name}, inplace=True)\n",
    "\n",
    "    metadata_preprocessing = {\n",
    "    \"resample_freq\": resample_freq,\n",
    "    \"aggregation_func\": aggregation_func,\n",
    "    \"interpolation_method\": interpolation_method,\n",
    "    \"outlier_cols\": outlier_cols,\n",
    "    }\n",
    "\n",
    "    output ={\n",
    "        \"df_resampled_interpolated\": df_resampled_interpolated,\n",
    "        \"metadata_preprocessing\": metadata_preprocessing\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "def create_cv_hyperparameters_model(\n",
    "        df, \n",
    "        hyperparameters_preprocessing,\n",
    "        hyperparameters_model_space,\n",
    "        hyperparameters_specific_regressor_args,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and execute cross-validation experiments with optimized hyperparameter combinations.\n",
    "\n",
    "    This function dynamically generates all possible combinations of generic parameters and model-specific\n",
    "    hyperparameters for a set of machine learning experiments. It then executes the experiments concurrently\n",
    "    using the generated hyperparameter configurations.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "            The raw dataframe containing the time-series data to be preprocessed and used for the cross-validation pipeline.\n",
    "\n",
    "    hyperparameter_model_space : dict\n",
    "            A dictionary defining the generic parameters and their possible values.\n",
    "            These parameters are common across all models and include:\n",
    "            - `ini_train` (list of str): List of start dates for training periods.\n",
    "            - `fin_train` (list of str): List of end dates for training periods.\n",
    "            - `fin_test` (list of str): List of end dates for testing periods.\n",
    "            - `model_sklearn_name` (list of str): List of model names from scikit-learn to evaluate.\n",
    "            - `n_lags` (list of int): Number of lag features to include in the models.\n",
    "            - `n_leads` (list of int): Number of lead features to include in the models.\n",
    "            - `X_name_features` (list of list of str): Feature subsets to include as predictors in the models.\n",
    "            Other parameters can also be included as required.\n",
    "\n",
    "    hyperparameters_specific_regressor_args : dict\n",
    "            A dictionary mapping each `model_sklearn_name` to its corresponding hyperparameter domains.\n",
    "            Each model's domain is defined as a dictionary of hyperparameter names and their possible values. \n",
    "            Example:\n",
    "            {\n",
    "            \"ARDRegression\": {\n",
    "                    \"max_iter\": [200, 300],\n",
    "                    \"tol\": [0.001, 0.01],\n",
    "                    \"alpha_1\": [1e-06, 1e-05],\n",
    "            },\n",
    "            \"Ridge\": {\n",
    "                    \"alpha\": [0.1, 1.0, 10.0],\n",
    "                    \"solver\": [\"auto\", \"svd\"]\n",
    "            }\n",
    "            }\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "        The function does not return any value. Instead, it generates the hyperparameter combinations and\n",
    "        executes the experiments concurrently by passing the configurations to the `create_model_machine_learning_algorithm`\n",
    "        function which manage all persistently with folder structure.\n",
    "\n",
    "    Workflow:\n",
    "    ---------\n",
    "    #TODO: Add an explanation/workflow diagram to illustrate the steps in the function.\n",
    "\n",
    "    Example Usage:\n",
    "    --------------\n",
    "    hyperparameter_model_space = {\n",
    "        \"ini_train\": [\"2023-04-18\", \"2023-05-01\"],\n",
    "        \"fin_train\": [\"2023-04-25\", \"2023-05-08\"],\n",
    "        \"fin_test\": [\"2023-04-27\", \"2023-05-10\"],\n",
    "        \"model_sklearn_name\": [\"Ridge\", \"ARDRegression\"],\n",
    "        \"n_lags\": [1, 5],\n",
    "        \"n_leads\": [5, 10],\n",
    "        \"X_name_features\": [[\"feature1\", \"feature2\"], [\"feature3\", \"feature4\"]],\n",
    "    }\n",
    "\n",
    "    model_specific_args = {\n",
    "            \"Ridge\": {\n",
    "            \"alpha\": [0.1, 1.0],\n",
    "            \"solver\": [\"auto\", \"svd\"]\n",
    "            },\n",
    "            \"ARDRegression\": {\n",
    "            \"max_iter\": [200],\n",
    "            \"tol\": [0.001],\n",
    "            }\n",
    "    }\n",
    "\n",
    "    create_cv_hyperparameters_model(hyperparameter_model_space, model_specific_args) \n",
    "    \"\"\"\n",
    "    def create_dataframe_combinations(df,parameter_space):\n",
    "            \"\"\"\n",
    "            Generate preprocessed dataframes based on combinations of preprocessing parameters.\n",
    "\n",
    "            This function dynamically generates all possible combinations of preprocessing parameters\n",
    "            specified in the `parameter_space` dictionary, applies the preprocessing to the given dataframe,\n",
    "            and returns a list of resulting preprocessed dataframes.\n",
    "\n",
    "            Parameters:\n",
    "            ----------\n",
    "            df : pd.DataFrame\n",
    "                    The raw dataframe containing the time-series data to be preprocessed.\n",
    "            parameter_space : dict\n",
    "                    A dictionary defining the preprocessing parameters and their possible values.\n",
    "                    The keys in the dictionary represent parameter names, and the values are lists of possible\n",
    "                    values for those parameters. The expected keys include:\n",
    "                    - `df` (pd.DataFrame): The raw dataframe to be preprocessed. It should be included in the\n",
    "                    `parameter_space` dictionary under the key `\"df\"`.\n",
    "                    - `resample_freq` (list of str): Frequencies for resampling the time-series data.\n",
    "                    - `aggregation_func` (list of str): Aggregation functions to apply during resampling.\n",
    "                    - `interpolation_method` (list of str): Methods to use for interpolating missing values.\n",
    "                    - `target_variable` (list of str): Names of the columns to set as the target variable.\n",
    "                    - `pivot` (list of bool): Whether to apply a pivot operation.\n",
    "                    - `pivot_index` (list of list of str): Columns to use as the index in the pivot table.\n",
    "                    - `pivot_columns` (list of list of str): Columns to use as the columns in the pivot table.\n",
    "                    - `pivot_values` (list of list of str): Columns to use as the values in the pivot table.\n",
    "                    - `subset_cols` (list of list of str): Columns to subset the dataframe to.\n",
    "                    - `target_column_name` (list of str): New names for the target variable column.\n",
    "\n",
    "            Returns:\n",
    "            -------\n",
    "            list\n",
    "                    A list of preprocessed dataframes, each generated using a unique combination of the parameters.\n",
    "\n",
    "            Example Usage:\n",
    "            --------------\n",
    "            parameter_space = {\n",
    "                    \"df\": raw_df, \n",
    "                    \"resample_freq\": [\"60S\", \"30S\"],\n",
    "                    \"aggregation_func\": [\"mean\", \"median\"],\n",
    "                    \"interpolation_method\": [\"linear\", \"quadratic\"],\n",
    "                    \"target_variable\": [\"00-eco2\"],\n",
    "                    \"pivot\": [True, False],\n",
    "                    \"pivot_index\": [[\"timestamp\", \"id_device\"]],\n",
    "                    \"pivot_columns\": [[\"id_variable\"]],\n",
    "                    \"pivot_values\": [[\"value\"]],\n",
    "                    \"subset_cols\": [[\"timestamp\", \"id_device\", \"id_variable\", \"value\"]],\n",
    "                    \"target_column_name\": [\"y\"]\n",
    "            }\n",
    "            preprocessed_dataframes = create_dataframe_combinations(parameter_space)\n",
    "            for df in preprocessed_dataframes:\n",
    "                    print(df)\n",
    "            \"\"\"\n",
    "            keys, values = zip(*parameter_space.items())\n",
    "\n",
    "            return [\n",
    "                    preprocess_and_standardize_dataframe(\n",
    "                        df=df,  \n",
    "                        resample_freq=params[\"resample_freq\"],\n",
    "                        aggregation_func=params[\"aggregation_func\"],\n",
    "                        interpolation_method=params[\"interpolation_method\"],\n",
    "                        target_variable=params.get(\"target_variable\"),\n",
    "                        outlier_cols=params.get(\"outlier_cols\"),\n",
    "                        pivot=params[\"pivot\"],\n",
    "                        pivot_index=params.get(\"pivot_index\"),\n",
    "                        pivot_columns=params.get(\"pivot_columns\"),\n",
    "                        pivot_values=params.get(\"pivot_values\"),\n",
    "                        subset_cols=params.get(\"subset_cols\"),\n",
    "                        target_column_name=params.get(\"target_column_name\"),\n",
    "                    )\n",
    "                    for combination in product(*values)\n",
    "                    for params in [dict(zip(keys, combination))]\n",
    "                ]\n",
    "\n",
    "\n",
    "    def generate_hyperparameters_machine_learning(parameter_space, model_specific_args, metadata_preprocessing):\n",
    "        \"\"\"\n",
    "        Generate unique hyperparameter combinations for machine learning experiments.\n",
    "\n",
    "        This function combines generic parameters and model-specific hyperparameters into dictionaries\n",
    "        representing all possible configurations.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        parameter_space : dict\n",
    "                Generic parameters shared across all models, such as training/testing periods, feature configurations,\n",
    "                and model names (`model_sklearn_name`).\n",
    "\n",
    "        model_specific_args : dict\n",
    "                Hyperparameter domains for each model, mapped by `model_sklearn_name`.\n",
    "\n",
    "        metadata_preprocessing : list\n",
    "                List of metadata dictionaries corresponding to the preprocessing steps applied to each dataframe.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        list\n",
    "                A list of dictionaries, where each dictionary contains a unique combination of:\n",
    "                - Generic parameters (`parameter_space`).\n",
    "                - Model-specific hyperparameters (`model_specific_args`).\n",
    "                - Preprocessing metadata (`metadata_preprocessing`).\n",
    "        \"\"\"\n",
    "        generic_keys, generic_values = zip(*((k, v) for k, v in parameter_space.items() if k != \"model_sklearn_name\"))\n",
    "        model_names = parameter_space.get(\"model_sklearn_name\", [])\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                **dict(zip(generic_keys, generic_comb)),\n",
    "                \"model_sklearn_name\": model,\n",
    "                \"metadata_preprocessing\": metadata,\n",
    "                \"machine_learning_model_args\": dict(zip(model_args_keys, model_args_comb))\n",
    "            }\n",
    "            for generic_comb, metadata in zip(product(*generic_values), metadata_preprocessing)\n",
    "            for model in model_names\n",
    "            for model_args_keys, model_args_values in [(list(model_specific_args[model].keys()), list(model_specific_args[model].values()))]\n",
    "            for model_args_comb in product(*model_args_values)\n",
    "        ]\n",
    "    \n",
    "    dfs_preprocessed_and_metadata = create_dataframe_combinations(\n",
    "        df=df, \n",
    "        parameter_space =hyperparameters_preprocessing\n",
    "        )\n",
    "    \n",
    "    dfs_preprocessed = [df[\"df_resampled_interpolated\"] for df in dfs_preprocessed_and_metadata]\n",
    "    metadata_preprocessing = [df[\"metadata_preprocessing\"] for df in dfs_preprocessed_and_metadata]\n",
    "    \n",
    "    hyperparameters_model_space[\"tidy_data\"] = dfs_preprocessed\n",
    "\n",
    "    hyperparameters = generate_hyperparameters_machine_learning(\n",
    "    parameter_space=hyperparameters_model_space, \n",
    "    model_specific_args=hyperparameters_specific_regressor_args, \n",
    "    metadata_preprocessing=metadata_preprocessing\n",
    "    )\n",
    "\n",
    "    return execute_concurrently(create_model_machine_learning_algorithm, hyperparameters)\n",
    "\n",
    "\n",
    "hyperparameters_preprocessing = {\n",
    "#     \"df\": [df],\n",
    "    \"resample_freq\": [\"60S\", \"30S\"],\n",
    "    \"aggregation_func\": [\"mean\", \"median\"],\n",
    "    \"interpolation_method\": [\"linear\", \"quadratic\"],\n",
    "    \"target_variable\": [\"00-eco2\"],\n",
    "    \"pivot\": [True],\n",
    "    \"pivot_index\": [[\"timestamp\", \"id_device\"]],\n",
    "    \"pivot_columns\": [[\"id_variable\"]],\n",
    "    \"pivot_values\": [[\"value\"]],\n",
    "    \"subset_cols\": [[\"timestamp\", \"id_device\", \"id_variable\", \"value\"]],\n",
    "    \"target_column_name\": [\"y\"]\n",
    "}\n",
    "\n",
    "hyperparameters_model_space = {\n",
    "#     \"tidy_data\": [df_preprocessed],\n",
    "    \"ini_train\": [\"2023-04-18 00:00:00+00:00\", \"2023-04-19 00:00:00+00:00\"],\n",
    "    \"fin_train\": [\"2023-04-25 00:00:00+00:00\", \"2023-04-26 00:00:00+00:00\"],\n",
    "    \"fin_test\": [\"2023-04-26 00:00:00+00:00\"],\n",
    "    \"model_sklearn_name\": [\"ARDRegression\"],\n",
    "    \"n_lags\": [5, 10],\n",
    "    \"n_leads\": [5, 10],\n",
    "    \"X_name_features\": [['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp', '02-pres']],\n",
    "    \"Y_name_features\": [\"y\"],\n",
    "    \"lag_columns\": [['04-diaq', '01-hum', '01-tvoc', '03-siaq', '00-temp', '02-pres', 'y']],\n",
    "    \"lead_columns\": [\"y\"],\n",
    "    \"scale_in_preprocessing\": [True],\n",
    "    \"name_time_column\": [\"timestamp\"],\n",
    "    \"save_preprocessing\": [True],\n",
    "    \"path_to_save_model\": [\"paper\"],\n",
    "    \"folder_name_model\": [\"ARDRegression\"],\n",
    "    \"folder_name_time_execution\": [\"execution-time-no-defined\"],\n",
    "    \"folder_name_preprocessed_data\": [\"preprocessed-data-to-use-in-model\"],\n",
    "    \"measure_time\": [True],\n",
    "    \"logger\": [None],\n",
    "    \"kwargs_save_object\": [{\"rename_if_exists\": True}],\n",
    "}\n",
    "\n",
    "hyperparameters_specific_regressor_args = {\n",
    "    \"ARDRegression\": {\n",
    "        \"max_iter\": [200, 300],\n",
    "        \"tol\": [0.001, 0.01],\n",
    "        \"alpha_1\": [1e-06, 1e-05],\n",
    "    }\n",
    "}\n",
    "\n",
    "df = pd.read_csv(r'..\\data\\instants_data_saved\\2023-07-04_12-09-22.csv')\n",
    "df = df.query(\"id_device == 'DBEM003'\").reset_index(drop=True)\n",
    "prepare_dataframe_from_db_cols_for_query = [\n",
    "    \"00-eco2\",\n",
    "    \"00-temp\",\n",
    "    \"01-hum\",\n",
    "    \"01-tvoc\",\n",
    "    \"02-pres\",\n",
    "    \"03-siaq\",\n",
    "    \"04-diaq\"\n",
    "]\n",
    "# Prepare dataframe with selected columns\n",
    "df = prepare_dataframe_from_db(\n",
    "    df=df,\n",
    "    cols_for_query=prepare_dataframe_from_db_cols_for_query,\n",
    ")\n",
    "\n",
    "test = create_cv_hyperparameters_model(\n",
    "        df = df,\n",
    "        hyperparameters_preprocessing = hyperparameters_preprocessing,\n",
    "        hyperparameters_model_space = hyperparameters_model_space,\n",
    "        hyperparameters_specific_regressor_args = hyperparameters_specific_regressor_args\n",
    ")\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_data</th>\n",
       "      <th>id_device</th>\n",
       "      <th>id_sensor</th>\n",
       "      <th>id_variable</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>id_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:31:00</td>\n",
       "      <td>18.57</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:32:00</td>\n",
       "      <td>18.56</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:33:00</td>\n",
       "      <td>18.55</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:34:00</td>\n",
       "      <td>18.53</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DBEM003</td>\n",
       "      <td>sWEA</td>\n",
       "      <td>00-temp</td>\n",
       "      <td>2023-04-18 09:35:00</td>\n",
       "      <td>18.53</td>\n",
       "      <td>ºC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477901</th>\n",
       "      <td>3477902</td>\n",
       "      <td>DBEM007</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-11 13:25:00</td>\n",
       "      <td>179.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477902</th>\n",
       "      <td>3477903</td>\n",
       "      <td>DBEM007</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-11 14:10:00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477903</th>\n",
       "      <td>3477904</td>\n",
       "      <td>DBEM007</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-11 14:40:00</td>\n",
       "      <td>206.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477904</th>\n",
       "      <td>3477905</td>\n",
       "      <td>DBEM007</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-11 15:49:00</td>\n",
       "      <td>213.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477905</th>\n",
       "      <td>3477906</td>\n",
       "      <td>DBEM007</td>\n",
       "      <td>sAQU</td>\n",
       "      <td>01-tvoc</td>\n",
       "      <td>2023-05-11 17:58:00</td>\n",
       "      <td>182.00</td>\n",
       "      <td>ppb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3477906 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_data id_device id_sensor id_variable            timestamp   value  \\\n",
       "0              1   DBEM003      sWEA     00-temp  2023-04-18 09:31:00   18.57   \n",
       "1              2   DBEM003      sWEA     00-temp  2023-04-18 09:32:00   18.56   \n",
       "2              3   DBEM003      sWEA     00-temp  2023-04-18 09:33:00   18.55   \n",
       "3              4   DBEM003      sWEA     00-temp  2023-04-18 09:34:00   18.53   \n",
       "4              5   DBEM003      sWEA     00-temp  2023-04-18 09:35:00   18.53   \n",
       "...          ...       ...       ...         ...                  ...     ...   \n",
       "3477901  3477902   DBEM007      sAQU     01-tvoc  2023-05-11 13:25:00  179.00   \n",
       "3477902  3477903   DBEM007      sAQU     01-tvoc  2023-05-11 14:10:00  200.00   \n",
       "3477903  3477904   DBEM007      sAQU     01-tvoc  2023-05-11 14:40:00  206.00   \n",
       "3477904  3477905   DBEM007      sAQU     01-tvoc  2023-05-11 15:49:00  213.00   \n",
       "3477905  3477906   DBEM007      sAQU     01-tvoc  2023-05-11 17:58:00  182.00   \n",
       "\n",
       "        unit  id_location  \n",
       "0         ºC          NaN  \n",
       "1         ºC          NaN  \n",
       "2         ºC          NaN  \n",
       "3         ºC          NaN  \n",
       "4         ºC          NaN  \n",
       "...      ...          ...  \n",
       "3477901  ppb          NaN  \n",
       "3477902  ppb          NaN  \n",
       "3477903  ppb          NaN  \n",
       "3477904  ppb          NaN  \n",
       "3477905  ppb          NaN  \n",
       "\n",
       "[3477906 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'..\\data\\instants_data_saved\\2023-07-04_12-09-22.csv')\n",
    "# df = df.query(\"id_device == 'DBEM003'\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
